---
title: "Project 2"
author: "Camryn Burley, Anna Haikl, and Joseph Keogh"
date: "12-4-19"
abstract: "On our honor as students, we have neither given nor received aid on this assignment."
output:
  pdf_dCOument: default
  html_dCOument: default
---

```{r setup, include=FALSE}
#=======
#Anna's Setup
#=======
require("knitr")
datadir <- "/Users/annahaikl/Desktop/UVA/FALL 2019/4021/DATA/Air Quality"
sourcedir <-"/Users/annahaikl/Desktop/UVA/FALL 2019/4021/CODE"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
```

```{r setup, include = FALSE}
# Camryn Set Up
require("knitr")
datadir <- "/Users/camrynburley/Desktop/UVA/SYS4021/Data/AirQuality"
sourcedir <- "/Users/camrynburley/Desktop/UVA/SYS4021/RCode"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
```

# Load Data and Impute Missing Values
```{r, warning=FALSE}
setwd(datadir)

airquality = read.csv('AirQualityUCI.csv')

# replace -200 with NA
airquality[airquality == -200] <- NA

# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
  airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}

setwd(sourcedir)

# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]

# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', 
             ga.control=list(formula=paste(names(AQdata)[c(1:3)],'~ns(t,2)')))

# set airquality to imputed data
AQdata <- i$filled.dataset

# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
```

# Create Testing and Training Data
```{r}
# the index to split the data on
separationIndex <- nrow(dailyAQ)-6

# split the data
air.train <- dailyAQ[1:separationIndex-1,]
air.test <- dailyAQ[separationIndex:nrow(dailyAQ),]

# making sure no data was duplicated or lost
a <- nrow(dailyAQ)
b <- nrow(air.train)
c <- nrow(air.test)

a
b
c
```

# Data Summary
```{r}
summary(air.train)
```
The data is from March 2004 through April 2005. We are modeling the ambient daily maximum carbon monoxide (CO) and nitrogen dioxide (NO2) concentrations. 

# Univariate Time Series for CO
## Visualize the Data
```{r}
# create time series
CO.ts <- ts(air.train$CO.GT.)

# visualize raw data
plot(CO.ts)
```
There is no extremely obvious trend from the plot of the time series. There may be some seasonality, but we are unsure as of now if this fluctuation is from seasonality or if it is random.

```{r}
# periodogram
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')
```
Based on the periodogram, there are multiple possibilities for the period of a seasonal component. There are a few spikes, each of which indicate a possible frequency/period to explain the seasonality of the data. We predict that if the seasonality is significant in the model, it will be based on a complex wave. 

## Seasonality
### Finding Potential Periods
```{r}
# sort the frequencies based on influence
sorted.spec <- sort(pg.CO$spec, decreasing=T, index.return=T)

# convert to periods
sorted.omegas <- pg.CO$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.CO$freq[sorted.spec$ix]

# the cutoff for influential
CO.pg.cutoff <- 5

# the top periods
print('top periods')
sorted.Ts[1:CO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas[1:CO.pg.cutoff]

# visual
CO.pg.box <- boxplot(sorted.Ts[1:CO.pg.cutoff], main="Period Boxplot")

# the average influential period
print('mean of top periods')
CO.pg.box.mean <- CO.pg.box$stats[3]
print(CO.pg.box.mean)

# plot top periods
plot(sorted.Ts[1:CO.pg.cutoff], main = "Top Periods")
```
We found the frequencies of the largest spikes in the periodogram graph and converted them to periods by taking 1/the frequency. The five largest spikes correspond to periods of 384, 192, 128, 96, and 76.8 days. We considered these our "top" choices for periods to explain seasonality.  
We are concerned that the reason we are seeing a period of 384 days is because this is close to the length of the data set and not because there is actual correlation between data values collected 384 days apart. We will investigate whether or not to use this period in the following sections.

### Create Model with Potential Periods
To begin, we made a model without the 384 day period but that included the other four periods.
```{r}
# assign potential periods to variables
CO.p1 <- sorted.Ts[1]
CO.p2 <- sorted.Ts[2]
CO.p3 <- sorted.Ts[3]
CO.p4 <- sorted.Ts[4]
CO.p5 <- sorted.Ts[5]

# CO.p1
# CO.p2
# CO.p3
# CO.p4
# CO.p5

# create time variable
time.CO<-c(1:length(CO.ts))

# model
CO.lm.top4 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top4)
```
This model will be compared to a model that only uses the first "important" period (i.e. the period associated with the largest spike in the periodogram, with the exception of the one corresponding to 384 days).

### Compare Larger Model with Model with Only First Important Period
```{r}
# actual model
CO.lm.top1 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + cos(2*pi*time.CO/CO.p2))

# model summary
summary(CO.lm.top1)

# anova
anova(CO.lm.top1, CO.lm.top4)
```
The p-value of the partial F-test is 0.0024, which is significant at the 0.05 level. We reject the null hypothesis, which means that the larger model contains at least one coefficient, not shared with the smaller model, that is significant. The larger model is better at explaining variability.

### Create Model with All Identified Periods
```{r}
# actual model
CO.lm.top5 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top5)

# compare with smaller model
anova(CO.lm.top4, CO.lm.top5)
```
We created the model that used all five periods identified from the periodogram. We compared it to the model without the 384-day period using a partial F test. The test is significant at the 0.05 level, which means there is significant evidence to use the larger model. We will use the model with all five periods to explain seasonality in further analysis.

### Visual Inspection of Model
```{r}
plot(CO.ts)
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top5$fitted.values, col = "red")
```
We plotted the fitted values of the model in red over the graph of the time series data. We plotted the entire time series and also zoomed in to see t = [0, 100] and t = [100, 200]. The model follows the general trend of the data, but there are no small fluctuations, of which the data has many. We may need to add a term with a smaller period in order to capture these smaller fluctuations.

### Explore Adding Higher Frequency Components
```{r}
# visual for frequency
plot(sorted.omegas, xlim=c(0,10))

# visual for periods
plot(sorted.Ts, xlim=c(0,30))

# look at the 6th through 10th most influencial periods
next.low.period <- boxplot(sorted.Ts[6:10])$stats[3]
next.low.period
```
The average of the periods associated with the next five highest spikes of the periodogram is about 7 days. A period of around 7 days makes sense to us, as CO production could be vary weekly from people working and commuting.

### Add New Period to Model
We made a new model with all five periods in our previous model and the addition of the new period around 7 days.
```{r}
CO.p6 <- next.low.period

# model
CO.lm.top6 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4) +
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5) +
                         sin(2*pi*time.CO/CO.p6) + 
                         cos(2*pi*time.CO/CO.p6))

# model summary
summary(CO.lm.top6)

# visual inspection
plot(CO.ts)
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top6$fitted.values, col = "red")
```
Upon visually inspecting this new model, we see smaller fluctuations, which we wanted. However, we do see that the peaks of the smaller waves do not consistently match up with where the data has a peak, based on the zoomed in graphs.  
After determining if there is a significant trend, we will compare the potential trend and seasonality models with five and 6 periods to determine which one will comprise our final linear model.

## Trend
### Model Time Series Based on Time
```{r}
# model
CO.lm.trend <- lm(CO.ts ~ time.CO)

# summary analysis
summary(CO.lm.trend)
```
The p-value is 0.00097, so there is a significant trend in the data.

### Visualize Trend
```{r}
plot(CO.ts)
abline(CO.lm.trend, col='red')
```

### Model Comparison: Trend and Seasonality Together
```{r}
# model with trend and 5 periods
CO.seasonal5.trend <- lm(CO.ts ~ CO.lm.trend$effects + CO.lm.top5$effects)

# model with trend and 6 periods 
CO.seasonal6.trend <- lm(CO.ts ~ CO.lm.trend$effects + CO.lm.top6$effects)
```

#### Visual Comparison
```{r}

model1 <- CO.seasonal5.trend
plot(CO.ts)
lines(model1$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(model1$fitted.values, col = "red")

model2 <- CO.seasonal6.trend
plot(CO.ts)
lines(model2$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(model2$fitted.values, col = "red")
```
Based on visual inspection, both models are pretty good, especially at modeling the data at the beginning of the time series. After that, while the peaks are not of the same magnitude as those of the data, they occur at relatively the same x-value in both plots. The differences in the models are slight, which makes it difficult to determine the best one by eye. 

#### Comparison Using Metrics
```{r}
# Adjusted R^2: model with trend and 5 periods
summary(CO.seasonal5.trend)$adj.r.squared

# AIC: model with trend and 5 periods
AIC(CO.seasonal5.trend)

# Adjusted R^2: model with trend and 6 periods
summary(CO.seasonal6.trend)$adj.r.squared

# AIC: model with trend and 6 periods
AIC(CO.seasonal6.trend)
```
The adjusted R^2 of the model that includes the trend and 5 periods is 0.258. The adjusted R^2 of the model that includes the trend and 6 periods is 0.259. Based on adjusted R^2, we would select the model with 6 periods, though they are very close based on this metric and neither value is particularly close to 1.  
The AIC of the model with 5 periods is 1474.224. The AIC of the model with 6 periods is 1473.733. Based on AIC, we would choose the model with 6 periods, because it has the smaller AIC value. Again, the values are very similar, though.

#### Diagnostics
**Residuals vs. Fitted**
```{r}
plot(CO.seasonal5.trend, which = 1)
plot(CO.seasonal6.trend, which = 1)
```
The mean of the residuals is not 0 and the variance is not constant for either model. The relationship evident in the plots indicates a lack of fit.

\pagebreak
**QQ Plot**
```{r}
plot(CO.seasonal5.trend, which = 2)
plot(CO.seasonal6.trend, which = 2)
```
The residuals are approximately normal for both models, though the tails show some deviation from normality.

\pagebreak
**Scale-Location Plot**
```{r}
plot(CO.seasonal5.trend, which = 3)
plot(CO.seasonal6.trend, which = 3)
```
The data appears to be clustered together in both plots, and the mean is not centered at 0.

\pagebreak
**Residuals vs. Leverage**
```{r}
plot(CO.seasonal5.trend, which = 5)
plot(CO.seasonal6.trend, which = 5)
```
In both plots, there is one point, which is the same data point, with a Cook's distance larger than 1. There is also one shared point that has a Cook's distance of approximately 0.5.

\pagebreak
```{r}
# plot Cook's distances
plot(CO.seasonal5.trend,labels.id = NULL, which = 4)
plot(CO.seasonal6.trend,labels.id = NULL, which = 4)
```
These plots show that it is the same two points for each model with high Cook's distances.

Both models perform very similarly in the diagnostics.

### Choose Trend + Seasonal Model
```{r}
CO.lm <- CO.seasonal6.trend
```
We have chosen the model with the trend and top six identified periods to explain seasonality, as it performed better than the model with trend and five periods in Adjusted R^2 and AIC. Since the diagnostics for both models were similar, these criteria were used to make the decision.

## Model Residuals
### ACF and PACF
```{r}
# ACF and PACF
acf(CO.ts)
pacf(CO.ts)
```
The ACF is approximately sinusoidal. The PACF does not cut off after a certain number of lags and has some sinusoidal behavior. We predict that there will be autoregressive and moving average terms in the model of the residuals.  
Based on the PACF, potential values for p for the autoregressive portion of the model are 4 and 8.  
Based on the ACF, potential values for q for the moving average portion of the model are 4 and 11.  
Additionally, we are unsure of the stationarity of the data, as we know there is a trend and the ACF appears to have some linear decay at the very beginning. This is a key assumption that must be met, so we will test models using the time series itself (d = 0) and the first differences (d = 1).

### ARIMA Models
We tested the possible combinations of our p, d, and q values.
```{r}
# get residuals
e.ts.CO <-ts(CO.lm$residuals)

# 4, 0, 4
CO.arima404 <- arima(e.ts.CO, order = c(4,0,4), include.mean = FALSE)
summary(CO.arima404)
# AIC = 1391.31

# 4, 0, 11
CO.arima4011 <- arima(e.ts.CO, order = c(4,0,11), include.mean = FALSE)
summary(CO.arima4011)
# AIC = 1386.82

# 4, 1, 4
CO.arima414 <- arima(e.ts.CO, order = c(4,1,4), include.mean = FALSE)
summary(CO.arima414)
# AIC = 1396.22

# 4, 1, 11
CO.arima4111 <- arima(e.ts.CO, order = c(4,1,11), include.mean = FALSE)
summary(CO.arima4111)
# AIC = 1392.74

# 8, 0, 4
CO.arima804 <- arima(e.ts.CO, order = c(8,0,4), include.mean = FALSE)
summary(CO.arima804)
# AIC = 1374.6

# 8, 0, 11
CO.arima8011 <- arima(e.ts.CO, order = c(8,0,11), include.mean = FALSE)
summary(CO.arima8011)
# AIC = 1391.05

# 8, 1, 4
CO.arima814 <- arima(e.ts.CO, order = c(8,1,4), include.mean = FALSE)
summary(CO.arima814)
# AIC = 1378.37
# NaNs produced

# 8, 1, 11
CO.arima8111 <- arima(e.ts.CO, order = c(8,1,11), include.mean = FALSE)
summary(CO.arima8111)
# AIC = 1379.06
# NaNs produced
```
Based on AIC, the two best models are the ARIMA(4,0,11) and ARIMA(8,0,4) models.

After testing the possible values of p, d, and q that we identified, we also used the auto.arima function to generate another model.
```{r}
# auto.arima model
CO.residuals.auto <- auto.arima(e.ts.CO)

# summary
summary(CO.residuals.auto)
```
The ARIMA model is a 1,1,1 model. This means that there are autoregressive and moving average terms, where p = 1 and q = 1. Also, d = 1, meaning that the first differences were used to ensure stationarity, which is a key assumption to modeling the residuals. The AIC for this model is 1397.12.

### Diagnostics
```{r}
tsdiag(CO.arima4011, gof.lag = 20)
tsdiag(CO.arima804, gof.lag = 20)
tsdiag(CO.residuals.auto, gof.lag = 20)
```
The model that performs the best in diagnostics is the ARIMA(4,0,11) model. It has the most points with high p-values in the Ljung-Box statistic plot. Both of the other models see their p-values decrease as the lag increases.

### Choose Model for Residuals
```{r}
CO.residuals <- CO.arima4011
```

## Final Model
The final model includes a trend and seasonality, using 6 different periods (384, 192, 128, 96, 76.8, and 7.11 days). The ARIMA model of the residuals is a 4,0,11 model.

## Diagnostics
The residuals of the trend and seasonality linear model appear relatively normal, from the QQ plot; however, problems remain with the residuals vs. fitted and scale-location plots, indicating violation of assumptions and lack of fit. There are also two points with high Cook's distances. In the future, models should address these problems.
The diagnostic plot for the model of the residuals does not have problems. The p-value for the Ljung-Box stastic is above the dashed line for all of the points and approaches 1 for many of the points. The model of the residuals is adequate for up to 20 lags.


# Univariate Time Series for NO2
## Visualize the Data
```{r}
# create time series
NO.ts <- ts(air.train$NO2.GT.)

# visualize raw data
plot(NO.ts)
```
There appears to be an increasing trend, especially after about t = 150. There is also the potential for seasonality, but this fluctuation could be random.

```{r}
# periodogram
pg.NO <- spec.pgram(NO.ts,spans=9,demean=T,log='no')
```
Based on the periodogram, there are multiple possibilities for the period of a seasonal component. There are fewer spikes than the periodogram for CO. There are still spikes, though, each of which indicate a possible frequency/period to explain the seasonality of the data. We predict that if the seasonality is significant in the model, it will be based on a complex wave.

## Seasonality
### Finding Potential Periods
```{r}
# sort the frequencies based on influence
sorted.spec.NO <- sort(pg.NO$spec, decreasing = T, index.return=T)

# convert to periods
sorted.omegas.NO <- pg.NO$freq[sorted.spec.NO$ix]
sorted.Ts.NO <- 1/pg.NO$freq[sorted.spec.NO$ix]

plot(sorted.Ts.NO, xlim = c(1,20))

# the cutoff for influential
NO.pg.cutoff <- 15

# the top periods
print('top periods')
sorted.Ts.NO[1:NO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas.NO[1:NO.pg.cutoff]

# visual
NO.pg.box <- boxplot(sorted.Ts.NO[1:NO.pg.cutoff], main="Period Boxplot")

# the average influential period
print('mean of top periods')
NO.pg.box.mean <- NO.pg.box$stats[3]
print(NO.pg.box.mean)
```
We found the frequencies of the largest spikes in the periodogram graph and converted them to periods by taking 1/the frequency. The 15 largest spikes corresponded to periods ranging from 6.62 to 384 days. We considered these our "top" choices for periods to explain seasonality.  
The average influential period can be interpreted as on average, the seasons have a period of 48 days.

### Create Models with Potential Periods
We created models with the top 3, 5, 10, and 15 periods, to determine which was best to explain the seasonality of the data. We also created a model that used a period that was the average of several other periods that were close together.
```{r}
# assign top periods to variables
NO.p1 <- sorted.Ts.NO[1]
NO.p2 <- sorted.Ts.NO[2]
NO.p3 <- sorted.Ts.NO[3]
NO.p4 <- sorted.Ts.NO[4]
NO.p5 <- sorted.Ts.NO[5]
NO.p6 <- sorted.Ts.NO[6]
NO.p7 <- sorted.Ts.NO[7]
NO.p8 <- sorted.Ts.NO[8]
NO.p9 <- sorted.Ts.NO[9]
NO.p10 <- sorted.Ts.NO[10]
NO.p11 <- sorted.Ts.NO[11]
NO.p12 <- sorted.Ts.NO[12]
NO.p13 <- sorted.Ts.NO[13]
NO.p14 <- sorted.Ts.NO[14]
NO.p15 <- sorted.Ts.NO[15]

NO.pavg1 <- mean(c(sorted.Ts.NO[8],sorted.Ts.NO[9], sorted.Ts.NO[10], sorted.Ts.NO[11]))
NO.pavg2 <- mean(c(sorted.Ts.NO[12],sorted.Ts.NO[13], sorted.Ts.NO[14], sorted.Ts.NO[15]))

# create time variable
time.NO<-c(1:length(NO.ts))
```

Model with Top 3 Periods
```{r}
# model
NO.lm.top3 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3)) 

# model summary
summary(NO.lm.top3)
```

Model with Top 5 Periods
```{r}
# model
NO.lm.top5 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5)) 

# model summary
summary(NO.lm.top5)
```

Model with Top 10 Periods
```{r}
# model
NO.lm.top10 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10)) 

# model summary
summary(NO.lm.top10)
```

Model with Top 15 Periods
```{r}
# model
NO.lm.top15 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10) +
                         sin(2*pi*time.NO/NO.p11) + 
                         cos(2*pi*time.NO/NO.p11) + 
                         sin(2*pi*time.NO/NO.p12) + 
                         cos(2*pi*time.NO/NO.p12) +
                         sin(2*pi*time.NO/NO.p13) + 
                         cos(2*pi*time.NO/NO.p13) +
                         sin(2*pi*time.NO/NO.p14) + 
                         cos(2*pi*time.NO/NO.p14) +
                         sin(2*pi*time.NO/NO.p15) + 
                         cos(2*pi*time.NO/NO.p15)) 

# model summary
summary(NO.lm.top15)
```

Model with Averaged Periods 
```{r}
NO.lm.combined <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2)) 

# model summary
summary(NO.lm.combined)
```

### Model Comparison
```{r}
anova(NO.lm.top3, NO.lm.top5)
# small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top5, NO.lm.top10)
# small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top10, NO.lm.top15)
# large p-value suggests that the smaller model performs better 

anova(NO.lm.top10, NO.lm.combined)
# large p-value suggests that the smaller model performs better 
```
The partial F tests suggest that the model that includes the top 10 periods is better than the models with 3, 5, and 15 periods. The partial F test also suggests that the model with the averaged periods is better than the model with the top 10 periods. Both of these models will be further compared through metrics and diagnostics later, after we determine if there is a significant trend to be included.

```{r}
# visualize
plot(NO.ts)
lines(NO.lm.top10$fitted.values, col = "red")
lines(NO.lm.combined$fitted.values, col = "blue")

legend(0, 350, legend = c("Top 10 Periods", "Combined Periods"), col = c("red", "blue"), lwd = 1)
```
Upon visual inspection, both models get the basic shape of the time series correct, though the model with the averaged periods has smaller fluctuations that may better match the actual data. 

## Trend
### Model Time Series Based on Time
```{r}
# trend model
NO.lm.trend <- lm(NO.ts ~ time.NO)

# summary analysis
summary(NO.lm.trend)
```
The p-value is significant at the 0.05 level, which means that the trend is significant. 

### Visualize Trend
```{r}
plot(time.NO, NO.ts, type = "l")
abline(NO.lm.trend, col = "red")
```

### Model Comparison: Trend and Seasonality Together
```{r}
# model with trend + averaged periods
NO.seasonalavg.trend <- lm(NO.ts ~ time.NO + sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2))

# model with trend + 10 periods
NO.seasonal10.trend <- lm(NO.ts ~ time.NO + sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10))
```

#### Visual Comparison
```{r}
plot(NO.ts)
lines(NO.seasonalavg.trend$fitted.values, col = "blue")
lines(NO.seasonal10.trend$fitted.values, col = "red")
```
Based on visual inspection, the model with the averaged periods appears to better capture the fluctuations of the data, though both models match the general trend of the data.

#### Comparison Using Metrics
```{r}
# Adjusted R^2: model with trend and averaged periods
summary(NO.seasonalavg.trend)$adj.r.squared

# AIC: model with trend and averaged periods
AIC(NO.seasonalavg.trend)

# Adjusted R^2: model with trend and 10 periods
summary(NO.seasonal10.trend)$adj.r.squared

# AIC: model with trend and 10 periods
AIC(NO.seasonal10.trend)
```
The adjusted R^2 of the model that includes the trend and averaged periods is 0.5622. The adjusted R^2 of the model that includes the trend and 10 periods is 0.5621. Based on adjusted R^2, the models are essentially equivalent.  
The AIC of the model with averaged periods is 3821.945. The AIC of the model with 10 periods is 3823.9. Based on AIC, we would choose the model with averaged periods, because it has the smaller AIC value. The values are very similar, though.

#### Diagnostics
**Residuals vs. Fitted**
```{r}
plot(NO.seasonalavg.trend, which = 1)
plot(NO.seasonal10.trend, which = 1)
```
The mean of the residuals is approximately 0 and has fairly even spread above and below the x-axis for both models.

\pagebreak
**QQ Plot**
```{r}
plot(NO.seasonalavg.trend, which = 2)
plot(NO.seasonal10.trend, which = 2)
```
The residuals are approximately normal for both models, though the tails show some deviation from normality. The model with averaged periods appears to have slightly more normal residuals at the tails.

\pagebreak
**Scale-Location Plot**
```{r}
plot(NO.seasonalavg.trend, which = 3)
plot(NO.seasonal10.trend, which = 3)
```
While the mean is not centered at 0 for either plot, there appears to be relatively good spread in both plots.

\pagebreak
**Residuals vs. Leverage**
```{r}
plot(NO.seasonalavg.trend, which = 5)
plot(NO.seasonal10.trend, which = 5)
```
Neither plot has any points with Cook's distances greater than 0.5.

\pagebreak
```{r}
# plot Cook's distances
plot(NO.seasonalavg.trend,labels.id = NULL, which = 4)
plot(NO.seasonal10.trend,labels.id = NULL, which = 4)
```
Both models have low Cook's distances for all points.

Both models perform very similarly in the diagnostics.

### Choose Trend + Seasonal Model
```{r}
NO.lm <- NO.seasonalavg.trend
```
We have chosen the model with the trend and averaged periods to explain seasonality, as it performed slightly better than the model with trend and 10 periods in AIC, as well as being preferred after the partial F test. Since the diagnostics for both models were similar, AIC and the partial F test were used to make the decision.

## Model Residuals
### ACF and PACF
```{r}
# ACF and PACF
acf(NO.ts)
pacf(NO.ts)
```
The ACF has somewhat sinusoidal behavior and is significant for all 25 lags in view on the plot. There does not appear to be linear decay in the ACF, suggesting that the time series is stationary and the first differences do not need to be taken to meet the stationarity assumption.  
The PACF does not cut off after a certain number of lags and also has somewhat sinusoidal behavior. We predict that there will be autoregressive and moving average terms in the model of the residuals.  
Based on the PACF, potential values for p for the autoregressive portion of the model are 4 and 8.  
Based on the ACF, potential values for q for the moving average portion of the model are 5 and 11. 

### ARIMA Models
We tested the possible combinations of our p and q values.
```{r}
# get residuals
e.ts.NO <-ts(NO.lm$residuals)

# 4, 0, 5
NO.arima405 <- arima(e.ts.NO, order = c(4,0,5), include.mean = FALSE)
summary(NO.arima405)
# AIC = 3659.71

# 4, 0, 11
NO.arima4011 <- arima(e.ts.NO, order = c(4,0,11), include.mean = FALSE)
summary(NO.arima4011)
# AIC = 3636.05

# 8, 0, 5
NO.arima805 <- arima(e.ts.NO, order = c(8,0,5), include.mean = FALSE)
summary(NO.arima805)
# AIC = 3656.34
# NaNs produced

# 8, 0, 11
NO.arima8011 <- arima(e.ts.NO, order = c(8,0,11), include.mean = FALSE)
summary(NO.arima8011)
# produced an error, so was not included
```
Based on AIC, the two best models are the ARIMA(4,0,5) and ARIMA(4,0,11) models.

After testing the possible values of p and q that we identified, we also used the auto.arima function to generate another model.
```{r}
# auto.arima model
NO.residuals.auto <- auto.arima(e.ts.NO)

# summary
summary(NO.residuals.auto)
```
The ARIMA model is a 1,0,0 model. This means that there are autoregressive terms, where p = 1, but no moving average terms, since q = 0. Also, d = 0, meaning that the time series is stationary, which is a key assumption to modeling the residuals. The AIC for this model is 3725.46.

### Diagnostics
```{r}
tsdiag(NO.arima405, gof.lag = 20)
tsdiag(NO.arima4011, gof.lag = 20)
tsdiag(NO.residuals.auto, gof.lag = 20)
```
The model that performs the best in diagnostics is the ARIMA(4,0,11) model. It has the most points with high p-values in the Ljung-Box statistic plot. Both of the other models have fewer points with high p-values, meaning that the model is adequate up to fewer lags.

### Choose Model for Residuals
```{r}
NO.residuals <- NO.arima4011
```
This model has the lowest AIC and also the best diagnostic plot of the models considered.

## Final Model
The final model includes a trend and seasonality, using 9 different periods, two of which are the averages of 4 similar periods each. The ARIMA model of the residuals is a 4,0,11 model.

## Diagnostics
The residuals of the trend and seasonality linear model appear relatively normal, from the QQ plot. There are no points with high Cook's distances. The residuals vs. fitted and scale-location plots have minor problems; they could have more even spread and a mean even closer to zero, but overall they look good. In the future, another model could be identified that performs even better in regard to these diagnostics.  
In the diagnostic plot for the model of the residuals, the p-value for the Ljung-Box stastic is above the dashed line for 15 of the 20 lags, meaning that the model of the residuals is adequate for up to 15 lags. A future model could work to extend the model adequacy to all 20 lags of the plot.

# Multivariate Time Series
## Seasonality and Trends
We used the same linear models for the seasonality and trends that we discovered in our analysis of the univariate time series for CO and NO2. See above for how we modeled seasonal components and trends to produce these linear models.

## Autoregressive and Moving Average Terms
## Models
## Model Comparison
### Metrics
### Diagnostics
(mask the output of tested models whose diagnostics you don't discuss using include = FALSE)
## Final Model
## Diagnostics
what problems remain in the diagnostics of the final model?


# Forecasting
compare univariate and multivariate models visually and based on MSE


# Simulation from Univariate CO Model
```{r}
# CO univariate model = model of data + model of residuals
CO.uni <- CO.lm + CO.residuals # idk that this is the way to do this

# simulate 1 year of daily maximum CO concentrations
### fix this based on actual ar and ma terms
CO.uni.sim <- arima.sim(n = 365*1, list(ar = c(CO.uni$coef[1], CO.uni$coef[2]), ma = c(CO.uni$coef[3])), sd = sqrt(CO.uni$sigma2))

# make time series
CO.uni.sim.ts <- ts(CO.uni.sim)
```

## Visualization
```{r}
# plot simulated values with observations
plot(CO.ts, main = "Simulation from Univariate CO Model", col = "black")
lines(CO.uni.sim.ts, col = "red")
legend(0.6, 0.57, legend = c("Time Series Data", "Simulation"), col = c("black", "red"))
```
how does simulation compare visually with time series data?

## Trend
```{r}
# linear model for simulation
CO.sim.lm <- lm()
```
compare coefficient estimates

## Seasonality
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.CO
pg.CO.uni.sim <- spec.pgram(CO.uni.sim.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
compare periodograms (get periods?)

## Mean and Variance
```{r}
# mean of observations
mean(CO.ts)

# mean of simulation
mean(CO.uni.sim.ts)

# variance of observations
var(CO.ts)

# variance of simulation
var(CO.uni.sim.ts)
```
compare mean and variance

## Auto-Correlation
```{r}
# ACF of observations
acf(CO.ts)

# ACF of simulation
acf(CO.uni.sim.ts)
```
compare ACF

```{r}
# PACF of observations
pacf(CO.ts)

# PACF of simulation
pacf(CO.uni.sim.ts)
```
compare PACF

## Cross-Correlation
```{r}
# cross-correlation of observations
cor(air.train$CO.GT.)

# cross-correlation of simulation
cor(CO.uni.sim)
```
compare cross-correlation


# Simulation from Univariate NO2 Model
## Visualization
## Trend
## Seasonality
## Mean and Variance
## Auto-Correlation
## Cross-Correlation


# Simulation from Multivariate Model
## Visualization
## Trend
## Seasonality
## Mean and Variance
## Auto-Correlation
## Cross-Correlation
