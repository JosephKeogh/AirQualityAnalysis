---
title: "Project 2"
author: "Group Members' Names"
date: "Date"
output:
  pdf_dCOument: default
  html_dCOument: default
---

```{r setup, include=FALSE}
require("knitr")
datadir <- "C:/Users/JK/Google Drive/Acedemics/College/Fourth Year/Semester 7/Linear Statistical Models/Data/AirQualityData"
sourcedir <-"C:/Users/JK/Google Drive/Acedemics/College/Fourth Year/Semester 7/Linear Statistical Models/Code"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
```

# Load data and impute missing values
```{r, warning=FALSE}
setwd(datadir)

airquality = read.csv('AirQualityUCI.csv')

# replace -200 with NA
airquality[airquality == -200] <- NA

# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
  airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}

setwd(sourcedir)

# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]

# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', 
             ga.control=list(formula=paste(names(AQdata)[c(1:3)],'~ns(t,2)')))

# set airquality to imputed data
AQdata <- i$filled.dataset

# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
```

# create testing and training data
```{r}

# the index to split the data on
separationIndex <- nrow(dailyAQ)-6

# split the data
air.train <- dailyAQ[1:separationIndex-1,]
air.test <- dailyAQ[separationIndex:nrow(dailyAQ),]

# making sure no data was duplicated or lost
a <- nrow(dailyAQ)
b <- nrow(air.train)
c <- nrow(air.test)

a
b
c
```

# review the data
```{r}
summary(air.train)
```

Data from March 2004 - April 2005

Looking at different levels of chemicals in the air

# visualize the data
```{r}
# create time series
CO.ts <- ts(air.train$CO.GT.)

# visualize raw data
plot(CO.ts)

# periodogram
# this pumps out a different graph sometimes
  # is this because it is doing fast Fourier Transfer??
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')

# acf and pacf
acf(CO.ts)
pacf(CO.ts)

```

based on the periodogram there is not one main season, but possible multiple
-if there is seasonality it will be based on a complex wave

No obvious trend or seasonality

# grab the main periods
```{r}
# sort the frequencies based on influence
sorted.spec <- sort(pg.CO$spec, decreasing=T, index.return=T)

# convert to periods
sorted.omegas <- pg.CO$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.CO$freq[sorted.spec$ix]

# the cutoff for influencial
CO.pg.cutoff <- 5

# the top periods
print('top periods')
sorted.Ts[1:CO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas[1:CO.pg.cutoff]

# visual
CO.pg.box <- boxplot(sorted.Ts[1:CO.pg.cutoff], main="Period Boxplot")

# the average influencial period
print('mean of top periods')
CO.pg.box.mean <- CO.pg.box$stats[3]
print(CO.pg.box.mean)

# plot top periods
plot(sorted.Ts[1:CO.pg.cutoff])
```

The top 5 frequencies are 

    
# assign top periods to variables
```{r}
CO.p1 <- sorted.Ts[1]
CO.p2 <- sorted.Ts[2]
CO.p3 <- sorted.Ts[3]
CO.p4 <- sorted.Ts[4]
CO.p5 <- sorted.Ts[5]

CO.p1
CO.p2
CO.p3
CO.p4
CO.p5


```

    
# create model based on the top periods identified
```{r}
# create time variable
time.CO<-c(1:length(CO.ts))

# actual model
## not using the first period because it is basically the entire data set
CO.lm.top4 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top4)
```

# compare larger model with model with only first important period
```{r}
# actual model
CO.lm.top1 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2))

# model summary
summary(CO.lm.top1)

# anova
anova(CO.lm.top1, CO.lm.top4)
```


There is significant evidence to use the larger model

# include the largest period
```{r}
# actual model
CO.lm.top5 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top5)

# compare with smaller model
anova(CO.lm.top4, CO.lm.top5)
```

There is significant evidence to use the larger model

In my opinion the only reason we are seeing a period is because this is the length of the data set

# perfrom step analysis on large model
```{r}
CO.lm.step <- step(CO.lm.top5)
summary(CO.lm.step)
```

# visual inspection of large model
```{r}
plot(CO.ts)
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top5$fitted.values, col = "red")
```

model follows the general trend of the data

no small fuctuations though, may need to add smaller frequency

# visual inspection of step model
```{r}
plot(CO.ts)
lines(CO.lm.step$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.step$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.step$fitted.values, col = "red")
```

step model also follows the general trend of the data

no small fluctuations though, need to possible add higher frequency components in


# explore adding higher frequency components
```{r}

# visual for frequency
plot(sorted.omegas, xlim=c(0,10))

# visual for periods
plot(sorted.Ts, xlim=c(0,30))

# look at the 6th through 10th most influencial periods
next.low.period <- boxplot(sorted.Ts[6:10])$stats[3]
next.low.period


```

the mean of the next highest frequency is 1/7
- this would make sense that there is a period of 7 days for CO production due to the work week being 7 days

# add slightly higher frequency to model
```{r}

CO.p6 <- next.low.period

# actual model
CO.lm.top6 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4) +
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5) +
                         sin(2*pi*time.CO/CO.p6) + 
                         cos(2*pi*time.CO/CO.p6))

# model summary
summary(CO.lm.top6)

# visual inspection
plot(CO.ts)
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top6$fitted.values, col = "red")

```

# step analysis of higher frequency model
```{r}
# actual model
CO.lm.step.1 <- step(CO.lm.top6)

# model summary
summary(CO.lm.step.1)

# visual inspection
plot(CO.ts)
lines(CO.lm.step.1$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.step.1$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.step.1$fitted.values, col = "red")


```

# anova on two step functions
```{r}
anova(CO.lm.step, CO.lm.step.1)
```

There is enough evidence to reject the null at a 0.1 level, but this is not very statistically significant

We will take the larger function, it follows the data more closely, and has the fluctuations we are looking for

# choose a seasonal model
```{r}
CO.lm.seasonal <- CO.lm.step.1
```


# trend
# predict the time series based on time
```{r}
# the actual model
CO.lm.trend <- lm(CO.ts ~ time.CO)

# summary analysis
summary(CO.lm.trend)
```

The p-value is 0.00092 so there is  a significant trend in the data

# visualize trend
```{r}
plot(CO.ts)
abline(CO.lm.trend, col='red')
```

# test if adding trend to our seasonal model is worth while
```{r}
# the actual model
CO.seasonal.trend <- lm(CO.ts ~ CO.lm.trend$effects + CO.lm.seasonal$effects)

# visualize
model <- CO.seasonal.trend
plot(CO.ts)
lines(model$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(model$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(model$fitted.values, col = "red")

```

This model is pretty good, matching some of the high points in the beginning

# model the residuals

# throw arima model together
```{r}
# find the residuals
e.ts.CO <-ts(CO.seasonal.trend$residuals)

# the arima model
CO.residuals.auto <- auto.arima(e.ts.CO)

# summary
summary(CO.residuals.auto)

```

the arima model ended up being a 5,1,4 model

# choose a residual model
```{r}
CO.residuals <- CO.residuals.auto
```


# combine the model to have a total model
```{r}
CO.seasonal.trend.residuals <- lm(CO.ts ~ CO.seasonal.trend + CO.residuals)
```


# max level of NO2
```{r}
# create time series
NO.ts <- ts(air.train$NO2.GT.)

# visualize raw data
plot(NO.ts)

# periodogram
pg.NO <- spec.pgram(NO.ts,spans=9,demean=T,log='no')

# acf and pacf
acf(NO.ts)
pacf(NO.ts)

```

No obvious trend or seasonality based on raw data

based on periodogram there may be some seasonlity, but it is going to be based on complex waves

















