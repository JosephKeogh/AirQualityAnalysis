---
title: "Project 2"
author: "Camryn Burley, Anna Haikl, and Joseph Keogh"
date: "12-4-19"
abstract: "On our honor as students, we have neither given nor received aid on this assignment."
output:
  pdf_document: default
---

<<<<<<< HEAD
```{r setup, include = FALSE}
# #=======
# #Anna's Setup
# #=======
=======
```{r , include = FALSE}
#=======
#Anna's Setup
#=======
>>>>>>> 13f1fd4bd6a55d0bf6d33be4e18f8e085a211e15
# require("knitr")
# datadir <- "/Users/annahaikl/Desktop/UVA/FALL 2019/4021/DATA/Air Quality"
# sourcedir <-"/Users/annahaikl/Desktop/UVA/FALL 2019/4021/CODE"
# opts_knit$set(root.dir = sourcedir)
# library(forecast)
# library(mtsdi)
# library(MTS)
```

```{r setup, include = FALSE}
# # Camryn Set Up
# require("knitr")
# datadir <- "/Users/camrynburley/Desktop/UVA/SYS4021/Data/AirQuality"
# sourcedir <- "/Users/camrynburley/Desktop/UVA/SYS4021/RCode"
# opts_knit$set(root.dir = sourcedir)
# library(forecast)
# library(mtsdi)
# library(MTS)
```

<<<<<<< HEAD
```{r}
=======
```{r , include = FALSE}
>>>>>>> 13f1fd4bd6a55d0bf6d33be4e18f8e085a211e15
# Joey Set Up
# require("knitr")
# datadir <- "C:/Users/JK/Google Drive/Acedemics/College/Fourth Year/Semester 7/Linear Statistical Models/Data/AirQualityData"
# sourcedir <-"C:/Users/JK/Google Drive/Acedemics/College/Fourth Year/Semester 7/Linear Statistical Models/Code"
# opts_knit$set(root.dir = sourcedir)
# library(forecast)
# library(mtsdi)
# library(MTS)
```

# Load Data and Impute Missing Values
```{r, warning=FALSE}
setwd(datadir)

airquality = read.csv('AirQualityUCI.csv')

# replace -200 with NA
airquality[airquality == -200] <- NA

# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
  airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}

setwd(sourcedir)

# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]

# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', 
             ga.control=list(formula=paste(names(AQdata)[c(1:3)],'~ns(t,2)')))

# set airquality to imputed data
AQdata <- i$filled.dataset

# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
```

\pagebreak
# Create Testing and Training Data
```{r}
# the index to split the data on
separationIndex <- nrow(dailyAQ)-6

# split the data
air.train <- dailyAQ[1:separationIndex-1,]
air.test <- dailyAQ[separationIndex:nrow(dailyAQ),]

# making sure no data was duplicated or lost
a <- nrow(dailyAQ)
b <- nrow(air.train)
c <- nrow(air.test)

# a
# b
# c
```

# Data Summary
```{r}
summary(air.train)
```
The data is from March 2004 through April 2005. We are modeling the ambient daily maximum carbon monoxide (CO) and nitrogen dioxide (NO2) concentrations. 

\pagebreak
# Univariate Time Series for CO
## Visualize the Data
```{r}
# create time series
CO.ts <- ts(air.train$CO.GT.)

# visualize raw data
plot(CO.ts, main = "CO Time Series")
```
There appears to be some trend from looking at the plot of the time series (i.e. the mean is not constant for the whole time series). There may be some seasonality, but we are unsure as of now if this fluctuation is from seasonality or if it is random.

\pagebreak
```{r}
# periodogram
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')
```
Based on the periodogram, there are multiple possibilities for the period of a seasonal component. There are a few spikes, each of which indicate a possible frequency/period to explain the seasonality of the data. We predict that if seasonality is significant in the model, it will be based on a complex wave. This is because there are many options for the period of potential seasons. 

## Seasonality
### Finding Potential Periods
```{r}
# sort the frequencies based on influence
sorted.spec <- sort(pg.CO$spec, decreasing=T, index.return=T)

# convert to periods
sorted.omegas <- pg.CO$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.CO$freq[sorted.spec$ix]

# the cutoff for influential
CO.pg.cutoff <- 5

# the top periods
print('top periods')
sorted.Ts[1:CO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas[1:CO.pg.cutoff]

# visual
CO.pg.box <- boxplot(sorted.Ts[1:CO.pg.cutoff], main="Period Boxplot")

# the average influential period
print('mean of top periods')
CO.pg.box.mean <- CO.pg.box$stats[3]
print(CO.pg.box.mean)

# plot top periods
plot(sorted.Ts[1:CO.pg.cutoff], main = "Top Periods")
```
We found the frequencies of the largest spikes in the periodogram graph and converted them to periods by taking 1/the frequency. The five largest spikes correspond to periods of 384, 192, 128, 96, and 76.8 days. We considered these our "top" choices for periods to explain seasonality.  
We are concerned that the reason we are seeing a period of 384 days is because this is close to the length of the data set and not because there is actual correlation between data values collected 384 days apart. We will investigate whether or not to use this period in the following sections.

\pagebreak
### Create Model with Potential Periods
To begin, we made a model without the 384 day period but that included the other four periods.
```{r}
# assign potential periods to variables
CO.p1 <- sorted.Ts[1]
CO.p2 <- sorted.Ts[2]
CO.p3 <- sorted.Ts[3]
CO.p4 <- sorted.Ts[4]
CO.p5 <- sorted.Ts[5]

# CO.p1
# CO.p2
# CO.p3
# CO.p4
# CO.p5

# create time variable
time.CO<-c(1:length(CO.ts))

# model
CO.lm.top4 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top4)
```
Based on the model utility test, this model is significant at the 0.05 level, so we will continue to analyze its performance in comparison to other models. We will compare it to a model that only uses the first "important" period (i.e. the period associated with the largest spike in the periodogram, with the exception of the one corresponding to 384 days).

### Compare Larger Model with Model with Only First Important Period
```{r}
# actual model
CO.lm.top1 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + cos(2*pi*time.CO/CO.p2))

# model summary
summary(CO.lm.top1)

# anova
anova(CO.lm.top1, CO.lm.top4)
```
The p-value of the partial F test is 0.0024, which is significant at the 0.05 level. We reject the null hypothesis, which means that the larger model contains at least one coefficient, not shared with the smaller model, that is significant. As a result of this test, we have concluded that the larger model is better at explaining variability.

### Create Model with All Identified Periods
```{r}
# actual model
CO.lm.top5 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top5)

# compare with smaller model
anova(CO.lm.top4, CO.lm.top5)
```
We created a model that used all five periods identified from the periodogram. We compared it to the model without the 384-day period using a partial F test. The test is significant at the 0.05 level, which means there is significant evidence to use the larger model. We will use the model with all five periods to explain seasonality in further analysis.

\pagebreak
### Visual Inspection of Model
```{r}
plot(CO.ts, main = "Model with 5 Periods")
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100), main = "Model with 5 Periods (zoomed)")
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200), main = "Model with 5 Periods (zoomed)")
lines(CO.lm.top5$fitted.values, col = "red")
```
We plotted the fitted values of the model in red over the graph of the time series data. We plotted the entire time series and also zoomed in to see t = [0, 100] and t = [100, 200]. The model follows the general trend of the data, but there are no small fluctuations, of which the data has many. We may need to add a term with a smaller period in order to capture these smaller fluctuations.

\pagebreak
### Explore Adding Higher Frequency Components
```{r}
# visual for frequency
plot(sorted.omegas, xlim=c(0,10))

# visual for periods
plot(sorted.Ts, xlim=c(0,30))

# look at the 6th through 10th most influencial periods
next.low.period <- boxplot(sorted.Ts[6:10])$stats[3]
next.low.period
```
The average of the periods associated with the next five highest spikes of the periodogram is about 7 days (7.11). A period of around 7 days makes sense to us, as CO production could vary weekly from people working and commuting.

\pagebreak
### Add New Period to Model
We made a new model with all five periods in our previous model with the addition of the new period of around 7 days.
```{r}
CO.p6 <- next.low.period

# model
CO.lm.top6 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4) +
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5) +
                         sin(2*pi*time.CO/CO.p6) + 
                         cos(2*pi*time.CO/CO.p6))

# model summary
summary(CO.lm.top6)

# visual inspection
plot(CO.ts, main = "Model with 6 Periods")
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100), main = "Model with 6 Periods (zoomed)")
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200), main = "Model with 6 Periods (zoomed)")
lines(CO.lm.top6$fitted.values, col = "red")
```
Upon visually inspecting this new model, we see smaller fluctuations, which we wanted. However, we do see that the peaks of the smaller waves do not consistently match up with where the data has a peak, based on the zoomed in graphs.  
After determining if there is a significant trend, we will compare the potential trend and seasonality models with five and six periods to determine which one will be the best selection for our final linear model.

## Trend
### Model Time Series Based on Time
```{r}
# model
CO.lm.trend <- lm(CO.ts ~ time.CO)

# summary analysis
summary(CO.lm.trend)
```
The p-value is 0.00097, so there is a significant trend in the data.

### Visualize Trend
```{r}
plot(CO.ts, main = "Trend")
abline(CO.lm.trend, col='red')
```
This graph shows the trendline plotted in red over the time series.

\pagebreak
### Model Comparison: Trend and Seasonality Together
```{r}
# model with trend and 5 periods
CO.seasonal5.trend <- lm(CO.ts ~ time.CO + sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model with trend and 6 periods 
CO.seasonal6.trend <- lm(CO.ts ~ time.CO + sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4) +
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5) +
                         sin(2*pi*time.CO/CO.p6) + 
                         cos(2*pi*time.CO/CO.p6))

anova(CO.seasonal5.trend, CO.seasonal6.trend)
```
The p-value of the partial F test is large (not significant at the 0.05 level), which means that the smaller model is preferred. Based on this test, we would choose the model with trend and five periods.

\pagebreak
#### Visual Comparison
```{r}
model1 <- CO.seasonal5.trend
plot(CO.ts, main = "Model with Trend and 5 Periods")
lines(model1$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100), main = "Model with Trend and 5 Periods (zoomed)")
lines(model1$fitted.values, col = "red")

model2 <- CO.seasonal6.trend
plot(CO.ts, main = "Model with Trend and 6 Periods")
lines(model2$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100), main = "Model with Trend and 6 Periods (zoomed)")
lines(model2$fitted.values, col = "red")
```
Based on visual inspection, both models capture the overall trend of the data well. The model with trend and six periods has smaller fluctuations, instead of being a smooth curve like the other model, which visually appears to look more similar to the time series. Again, we see that the peaks of the model do not always occur at the same time value as the peaks of the data. 

#### Comparison Using Metrics
```{r}
# Adjusted R^2: model with trend and 5 periods
summary(CO.seasonal5.trend)$adj.r.squared

# AIC: model with trend and 5 periods
AIC(CO.seasonal5.trend)

# Adjusted R^2: model with trend and 6 periods
summary(CO.seasonal6.trend)$adj.r.squared

# AIC: model with trend and 6 periods
AIC(CO.seasonal6.trend)
```
The adjusted R^2 of the model that includes the trend and 5 periods is 0.185. The adjusted R^2 of the model that includes the trend and 6 periods is 0.187. Based on adjusted R^2, we would select the model with 6 periods, though they are very close based on this metric and neither value is particularly close to 1.  
The AIC of the model with 5 periods is 1519.205. The AIC of the model with 6 periods is 1520.075. Based on AIC, we would choose the model with 5 periods, because it has the smaller AIC value. Again, the values are very similar, though.

#### Diagnostics
**Residuals vs. Fitted**
```{r}
plot(CO.seasonal5.trend, which = 1)
plot(CO.seasonal6.trend, which = 1)
```
The mean of the residuals is approximately 0, but the variance is not constant for either model. There is less variance (less spread above and below the x-axis) on the left-hand side of the plot, and the variance increases to the right. The relationship evident in the plots indicates a lack of fit.

\pagebreak
**QQ Plot**
```{r}
plot(CO.seasonal5.trend, which = 2)
plot(CO.seasonal6.trend, which = 2)
```
The residuals are approximately normal for both models, though the tails, and the lower tails especially, show some deviation from normality.

\pagebreak
**Scale-Location Plot**
```{r}
plot(CO.seasonal5.trend, which = 3)
plot(CO.seasonal6.trend, which = 3)
```
The mean is not centered at 0 and there may be a slight pattern to the scatter in both plots.

\pagebreak
**Residuals vs. Leverage**
```{r}
plot(CO.seasonal5.trend, which = 5)
plot(CO.seasonal6.trend, which = 5)
```
Neither plot has any points with Cook's distances greater than 0.5.

\pagebreak
```{r}
# plot Cook's distances
plot(CO.seasonal5.trend,labels.id = NULL, which = 4)
plot(CO.seasonal6.trend,labels.id = NULL, which = 4)
```
These plots show that all of the points have small Cook's distances for both models.

Both models perform very similarly in the diagnostics. We do not feel that either model needs a log or Box Cox transformation to improve the diagnostics.

### Choose Trend + Seasonal Model
```{r}
# create the combined model
CO.lm <- CO.seasonal5.trend
```
Since both models performed similarly in metrics and diagnostics, we have chosen to use the model with the trend and top five identified periods to explain seasonality. It was preferred from the partial F test, and we feel that it is better to choose the simpler model since the two models have such similar performance in metrics and diagnostics.

\pagebreak
## Model Residuals
### ACF and PACF
```{r}
# ACF and PACF
acf(CO.ts)
pacf(CO.ts)
```
The ACF is approximately sinusoidal. The PACF does not cut off after a certain number of lags and has some sinusoidal behavior. We predict that there will be autoregressive and moving average terms in the model of the residuals.  
Based on the PACF, a potential value for p for the autoregressive portion of the model is 1. Since the first cutoff for the PACF is 1, we will also test a value of 2 for p, to see if that is better suited to modeling the residuals.  
Based on the ACF, a potential value for q for the moving average portion of the model is 3. We will also test values of 1 and 2 for q, since they are the other significant lags before the first cutoff in the ACF.  
Additionally, we are unsure of the stationarity of the data, as we know there is a trend and the ACF appears to have some linear decay at the very beginning. This is a key assumption that must be met, so we will test models using the time series itself (d = 0) and the first differences (d = 1).  

\pagebreak
### ARIMA Models
We tested the possible combinations of our p, d, and q values.
```{r}
# get residuals
e.ts.CO <-ts(CO.lm$residuals)

# 1, 0, 1
CO.arima101 <- arima(e.ts.CO, order = c(1,0,1), include.mean = FALSE)
summary(CO.arima101)
# AIC = 1435.68

# 1, 0, 2
CO.arima102 <- arima(e.ts.CO, order = c(1,0,2), include.mean = FALSE)
summary(CO.arima102)
# AIC = 1437.48

# 1, 0, 3
CO.arima103 <- arima(e.ts.CO, order = c(1,0,3), include.mean = FALSE)
summary(CO.arima103)
# AIC = 1439.4

# 1, 1, 1
CO.arima111 <- arima(e.ts.CO, order = c(1,1,1), include.mean = FALSE)
summary(CO.arima111)
# AIC = 1439.59

# 1, 1, 2
CO.arima112 <- arima(e.ts.CO, order = c(1,1,2), include.mean = FALSE)
summary(CO.arima112)
# AIC = 1440.02

# 1, 1, 3
CO.arima113 <- arima(e.ts.CO, order = c(1,1,3), include.mean = FALSE)
summary(CO.arima113)
# AIC = 1442.08

# 2, 0, 1
CO.arima201 <- arima(e.ts.CO, order = c(2,0,1), include.mean = FALSE)
summary(CO.arima201)
# AIC = 1414.33
# lowest

# 2, 0, 2
CO.arima202 <- arima(e.ts.CO, order = c(2,0,2), include.mean = FALSE)
summary(CO.arima202)
# AIC = 1430.8

# 2, 0, 3
CO.arima203 <- arima(e.ts.CO, order = c(2,0,3), include.mean = FALSE)
summary(CO.arima203)
# AIC = 1427.32

# 2, 1, 1
CO.arima211 <- arima(e.ts.CO, order = c(2,1,1), include.mean = FALSE)
summary(CO.arima211)
# AIC = 1439.67

# 2, 1, 2
CO.arima212 <- arima(e.ts.CO, order = c(2,1,2), include.mean = FALSE)
summary(CO.arima212)
# AIC = 1423.76
# second lowest

# 2, 1, 3
CO.arima213 <- arima(e.ts.CO, order = c(2,1,3), include.mean = FALSE)
summary(CO.arima213)
# AIC = 1435.73
```
Based on AIC, the two best models are the ARIMA(2,0,1) and ARIMA(2,1,2) models.

After testing the possible values of p, d, and q that we identified, we also used the auto.arima function to generate another model.
```{r}
# auto.arima model
CO.residuals.auto <- auto.arima(e.ts.CO, approximation = FALSE)

# summary
summary(CO.residuals.auto)
```
The ARIMA model is a 2,0,0 model. This means that there are autoregressive and moving average terms, where p = 2 and q = 2. Also, d = 0, meaning that the first differences were not needed to ensure stationarity, which is a key assumption to modeling the residuals. The AIC for this model is 1435.28.

\pagebreak
### Diagnostics
```{r}
tsdiag(CO.arima201, gof.lag = 20)
tsdiag(CO.arima212, gof.lag = 20)
tsdiag(CO.residuals.auto, gof.lag = 20)
```
Both the (2,0,1) and (2,1,2) models perform similarly in the diagnostic plot, though the (2,1,2) model has a slightly higher p-value for the sixth lag than the other model. The auto-generated (2,0,0) model is only adequate for four lags, as the p-value of the Ljung-Box statistic is not different from 0 (above the dashed line) for only the first four points. 

### Choose Model for Residuals
```{r}
summary(CO.residuals)
CO.residuals <- CO.arima201
```
The ARIMA(2,0,1) model has the smallest AIC of all of the models considered. It performs better than the auto-generated model, as it is adequate for more lags. Since it performs similarly to the ARIMA(2,1,2) model in the diagnostic plot but has a lower AIC, we decided to choose the ARIMA(2,0,1) model for the residuals.

## Final Model
The final model includes a trend and seasonality, using 5 different periods (384, 192, 128, 96, and 76.8 days). The ARIMA model of the residuals is a 7,1,9 model.

### create the final model
```{r}

# set the seed to keep consistent values
set.seed(1)

# quick fix to allow their code to work with ours
e.Tmin.lm <- CO.residuals

# simulate the arima values
# 365 was chosen because we are to simulate a year of data

# this is for the large arima function
# e.CO.sim <- arima.sim(n=365, 
#                       list(
#                             ar=c(
#                                 e.Tmin.lm$coef[1],e.Tmin.lm$coef[2],e.Tmin.lm$coef[3],
#                                 e.Tmin.lm$coef[4],e.Tmin.lm$coef[5],e.Tmin.lm$coef[6],
#                                 e.Tmin.lm$coef[7]
#                               ), 
#                             ma=c(
#                               e.Tmin.lm$coef[8],e.Tmin.lm$coef[9],e.Tmin.lm$coef[10],
#                               e.Tmin.lm$coef[11],e.Tmin.lm$coef[12],e.Tmin.lm$coef[13],
#                               e.Tmin.lm$coef[14],e.Tmin.lm$coef[15],e.Tmin.lm$coef[16]
#                               )
#                           ), 
#                             sd=sqrt(e.Tmin.lm$sigma2)
#                         )

# this is for the auto.arima function
e.CO.sim <- arima.sim(n=365, 
                      list(
                            ar=c(
                                e.Tmin.lm$coef[1],e.Tmin.lm$coef[2]
                              ), 
                            ma=c(
                              e.Tmin.lm$coef[3]
                              )
                          )
                        )

# the next time variable
# this will need to be changed based on what we are predicting
# right now doing 50 days
next.time.time <- c(1:(50))
next.time <- data.frame(time.CO = next.time.time)

# the mean prediction of the linear model based on the next times
CO.mean <- predict(CO.lm, newdata=next.time)

# combine the simulated residuals and the predicted value
CO.combined <- e.CO.sim + CO.mean

# plot the results
plot(CO.ts)
lines(CO.lm$fitted.values, col='red')
lines(CO.combined, col='cyan')

# output results
# e.CO.sim

```

TA mentioned that we can either do a difference or model the trend, but we do not have to do both

The final model includes a trend and seasonality, using 5 different periods (384, 192, 128, 96, and 76.8 days). The ARIMA model of the residuals is a 2,0,1 model.

### Diagnostics
The residuals of the trend and seasonality linear model appear relatively normal, excluding the lower tail, from the QQ plot; however, problems remain with the residuals vs. fitted plot, indicating lack of fit. In the future, models should address problems with the normality in the lower tail and the lack of fit.
The diagnostic plot for the model of the residuals shows that it is adequate for five or six lags. Future work could focus on increasing the number of lags for which the model is considered adequate.

\pagebreak
# Univariate Time Series for NO2
## Visualize the Data
```{r}
# create time series
NO.ts <- ts(air.train$NO2.GT.)

# visualize raw data
plot(NO.ts)
```
There appears to be an increasing trend, especially after about t = 150. There is also the potential for seasonality, but this fluctuation could instead be random.

\pagebreak
```{r}
# periodogram
pg.NO <- spec.pgram(NO.ts, spans = 9, demean = T, log = 'no')
```
Based on the periodogram, there are multiple possibilities for the period of a seasonal component. There are fewer spikes than the periodogram for CO. There are still spikes, though, each of which indicate a possible frequency/period to explain the seasonality of the data. We predict that if seasonality is significant in the model, it will be based on a complex wave.

\pagebreak
## Seasonality
### Finding Potential Periods
```{r}
# sort the frequencies based on influence
sorted.spec.NO <- sort(pg.NO$spec, decreasing = T, index.return=T)

# convert to periods
sorted.omegas.NO <- pg.NO$freq[sorted.spec.NO$ix]
sorted.Ts.NO <- 1/pg.NO$freq[sorted.spec.NO$ix]

plot(sorted.Ts.NO, xlim = c(1,20))

# the cutoff for influential
NO.pg.cutoff <- 15

# the top periods
print('top periods')
sorted.Ts.NO[1:NO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas.NO[1:NO.pg.cutoff]

# visual
NO.pg.box <- boxplot(sorted.Ts.NO[1:NO.pg.cutoff], main="Period Boxplot")

# the average influential period
print('mean of top periods')
NO.pg.box.mean <- NO.pg.box$stats[3]
print(NO.pg.box.mean)
```
We found the frequencies of the largest spikes in the periodogram graph and converted them to periods by taking 1/the frequency. The 15 largest spikes corresponded to periods ranging from 6.62 to 384 days. We considered these our "top" choices for periods to explain seasonality.  
The average influential period can be interpreted as on average, the seasons have a period of 48 days.

\pagebreak
### Create Models with Potential Periods
We created models with the top 3, 5, 10, and 15 periods, to determine which was best to explain the seasonality of the data. We did this because we predicted that the seasonality would be based on a complex wave, and we wanted to know how many different periods would be advantageous (i.e. explain more variance) in a model.  
We also created a model that used a period that was the average of several other periods that were close together. We noticed that top periods 8 through 11 were in the range of 34 to 48. We noticed that top periods 12 through 15 were all close to 7. We thought that since these sets of periods were clustered together, potentially their average would be better at explaining the variance in the model instead of adding separate predictors for each similar period.
```{r}
# assign top periods to variables
NO.p1 <- sorted.Ts.NO[1]
NO.p2 <- sorted.Ts.NO[2]
NO.p3 <- sorted.Ts.NO[3]
NO.p4 <- sorted.Ts.NO[4]
NO.p5 <- sorted.Ts.NO[5]
NO.p6 <- sorted.Ts.NO[6]
NO.p7 <- sorted.Ts.NO[7]
NO.p8 <- sorted.Ts.NO[8]
NO.p9 <- sorted.Ts.NO[9]
NO.p10 <- sorted.Ts.NO[10]
NO.p11 <- sorted.Ts.NO[11]
NO.p12 <- sorted.Ts.NO[12]
NO.p13 <- sorted.Ts.NO[13]
NO.p14 <- sorted.Ts.NO[14]
NO.p15 <- sorted.Ts.NO[15]

NO.pavg1 <- mean(c(sorted.Ts.NO[8],sorted.Ts.NO[9], sorted.Ts.NO[10], sorted.Ts.NO[11]))
NO.pavg2 <- mean(c(sorted.Ts.NO[12],sorted.Ts.NO[13], sorted.Ts.NO[14], sorted.Ts.NO[15]))

# create time variable
time.NO<-c(1:length(NO.ts))
```

Model with Top 3 Periods
```{r}
# model
NO.lm.top3 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3)) 
```

Model with Top 5 Periods
```{r}
# model
NO.lm.top5 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5)) 
```

Model with Top 10 Periods
```{r}
# model
NO.lm.top10 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10)) 
```

Model with Top 15 Periods
```{r}
# model
NO.lm.top15 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10) +
                         sin(2*pi*time.NO/NO.p11) + 
                         cos(2*pi*time.NO/NO.p11) + 
                         sin(2*pi*time.NO/NO.p12) + 
                         cos(2*pi*time.NO/NO.p12) +
                         sin(2*pi*time.NO/NO.p13) + 
                         cos(2*pi*time.NO/NO.p13) +
                         sin(2*pi*time.NO/NO.p14) + 
                         cos(2*pi*time.NO/NO.p14) +
                         sin(2*pi*time.NO/NO.p15) + 
                         cos(2*pi*time.NO/NO.p15)) 
```

Model with Averaged Periods 
```{r}
NO.lm.combined <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2)) 
```

### Model Comparison
```{r}
anova(NO.lm.top3, NO.lm.top5)
# small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top5, NO.lm.top10)
# small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top10, NO.lm.top15)
# large p-value suggests that the smaller model performs better 

anova(NO.lm.top10, NO.lm.combined)
# large p-value suggests that the smaller model performs better 
```
The partial F tests suggest that the model that includes the top 10 periods is better than the models with 3, 5, and 15 periods. The partial F test also suggests that the model with the averaged periods is better than the model with the top 10 periods. Both the model with 10 periods and the model with averaged periods will be further compared through metrics and diagnostics later, after we determine if there is a significant trend to be included.

\pagebreak
```{r}
# visualize
plot(NO.ts, main = "Comparison of Trend and Seasonal Models")
lines(NO.lm.top10$fitted.values, col = "red")
lines(NO.lm.combined$fitted.values, col = "blue")

legend(0, 350, legend = c("Top 10 Periods", "Averaged Periods"), col = c("red", "blue"), lwd = 1)
```
Upon visual inspection, both models get the basic shape of the time series correct, though the model with the averaged periods has smaller fluctuations that may better match the actual data. 

## Trend
### Model Time Series Based on Time
```{r}
# trend model
NO.lm.trend <- lm(NO.ts ~ time.NO)

# summary analysis
summary(NO.lm.trend)
```
The p-value is significant at the 0.05 level, which means that the trend is significant. 

### Visualize Trend
```{r}
plot(time.NO, NO.ts, type = "l", main = "Trend")
abline(NO.lm.trend, col = "red")
```
As we noticed earlier from looking at the time series, there is an upward trend to the data.

\pagebreak
### Model Comparison: Trend and Seasonality Together
```{r}
# model with trend + averaged periods
NO.seasonalavg.trend <- lm(NO.ts ~ time.NO + sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2))

# model with trend + 10 periods
NO.seasonal10.trend <- lm(NO.ts ~ time.NO + sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10))
```

\pagebreak
#### Visual Comparison
```{r}
plot(NO.ts, main = "Comparison of Models with Trend and Seasonality")
lines(NO.seasonalavg.trend$fitted.values, col = "blue")
lines(NO.seasonal10.trend$fitted.values, col = "red")
legend(0, 350, legend = c("Top 10 Periods", "Averaged Periods"), col = c("red", "blue"),
       lwd = 1)
```
Based on visual inspection, the model with trend and averaged periods appears to better capture the fluctuations of the data, though both models match the general trend of the data.

#### Comparison Using Metrics
```{r}
# Adjusted R^2: model with trend and averaged periods
summary(NO.seasonalavg.trend)$adj.r.squared

# AIC: model with trend and averaged periods
AIC(NO.seasonalavg.trend)

# Adjusted R^2: model with trend and 10 periods
summary(NO.seasonal10.trend)$adj.r.squared

# AIC: model with trend and 10 periods
AIC(NO.seasonal10.trend)
```
The adjusted R^2 of the model that includes the trend and averaged periods is 0.5622. The adjusted R^2 of the model that includes the trend and 10 periods is 0.5621. Based on adjusted R^2, the models are essentially equivalent.  
The AIC of the model with averaged periods is 3821.945. The AIC of the model with 10 periods is 3823.9. Based on AIC, we would choose the model with averaged periods, because it has the smaller AIC value. The values are very similar, though.

#### Diagnostics
**Residuals vs. Fitted**
```{r}
plot(NO.seasonalavg.trend, which = 1)
plot(NO.seasonal10.trend, which = 1)
```
The mean of the residuals is approximately 0 and has fairly even spread above and below the x-axis for both models. The variance appears to have a slight trend, where there is less spread above and below the x-axis to the left and slightly more on the right.

\pagebreak
**QQ Plot**
```{r}
plot(NO.seasonalavg.trend, which = 2)
plot(NO.seasonal10.trend, which = 2)
```
The residuals are approximately normal for both models, though the tails show some deviation from normality. The model with averaged periods appears to have slightly more normal residuals at the tails.

\pagebreak
**Scale-Location Plot**
```{r}
plot(NO.seasonalavg.trend, which = 3)
plot(NO.seasonal10.trend, which = 3)
```
While the mean is not centered at 0 for either plot, there appears to be relatively good spread in both plots.

\pagebreak
**Residuals vs. Leverage**
```{r}
plot(NO.seasonalavg.trend, which = 5)
plot(NO.seasonal10.trend, which = 5)
```
Neither plot has any points with Cook's distances greater than 0.5.

\pagebreak
```{r}
# plot Cook's distances
plot(NO.seasonalavg.trend,labels.id = NULL, which = 4)
plot(NO.seasonal10.trend,labels.id = NULL, which = 4)
```
Both models have low Cook's distances for all points.

Both models perform similarly in the diagnostics. We do not feel that either model needs a log or Box Cox transformation to improve the diagnostics.

### Choose Trend + Seasonal Model
```{r}
NO.lm <- NO.seasonalavg.trend
```
We have chosen the model with the trend and averaged periods to explain seasonality, as it performed slightly better in AIC than the model with trend and 10 periods, as well as being preferred after the partial F test. Since the diagnostics for both models were similar, AIC and the partial F test were used to make the decision. Though not a deciding factor in our choice, this model also has the advantage of having somewhat more normal residuals in the tails of the QQ plot.

\pagebreak
## Model Residuals
### ACF and PACF
```{r}
# ACF and PACF
acf(NO.ts)
pacf(NO.ts)
```
The ACF has somewhat sinusoidal behavior and is significant for all 25 lags in view on the plot. The first few lags could be seen as having linear decay, suggesting that the time series may not be stationary and the first differences may need to be taken to meet the stationarity assumption. Values for d of 0 and 1 will be tested in potential models.

The PACF does not cut off after a certain number of lags and also has somewhat sinusoidal behavior. We predict that there will be autoregressive and moving average terms in the model of the residuals.  
Based on the PACF, a potential value for p for the autoregressive portion of the model is 3. We will also test values of 1 and 2 for p, since they are the other significant lags before the first cutoff in the PACF.  
Based on the ACF, a potential value for q for the moving average portion of the model is 4. This is the point where the ACF stops decreasing, before increasing again, for the first time. Values of 1, 2, and 3 will also be tested for q, as these lags are also significant before the lag of 4.  

\pagebreak
### ARIMA Models
We tested the possible combinations of our p, d, and q values.
```{r}
# get residuals
e.ts.NO <-ts(NO.lm$residuals)

# 1, 0, 1
NO.arima101 <- arima(e.ts.NO, order = c(1,0,1), include.mean = FALSE)
summary(NO.arima101)
# AIC = 3726.77

# 1, 0, 2
NO.arima102 <- arima(e.ts.NO, order = c(1,0,2), include.mean = FALSE)
summary(NO.arima102)
# AIC = 3728.74

# 1, 0, 3
NO.arima103 <- arima(e.ts.NO, order = c(1,0,3), include.mean = FALSE)
summary(NO.arima103)
# AIC = 3728.22

# 1, 0, 4
NO.arima104 <- arima(e.ts.NO, order = c(1,0,4), include.mean = FALSE)
summary(NO.arima104)
# AIC = 3696.11
# lowest

# 1, 1, 1
NO.arima111 <- arima(e.ts.NO, order = c(1,1,1), include.mean = FALSE)
summary(NO.arima111)
# AIC = 3723.77

# 1, 1, 2
NO.arima112 <- arima(e.ts.NO, order = c(1,1,2), include.mean = FALSE)
summary(NO.arima112)
# AIC = 3725.16

# 1, 1, 3
NO.arima113 <- arima(e.ts.NO, order = c(1,1,3), include.mean = FALSE)
summary(NO.arima113)
# AIC = 3727.12

# 1, 1, 4
NO.arima114 <- arima(e.ts.NO, order = c(1,1,4), include.mean = FALSE)
summary(NO.arima114)
# AIC = 3726.51

# 2, 0, 1
NO.arima201 <- arima(e.ts.NO, order = c(2,0,1), include.mean = FALSE)
summary(NO.arima201)
# AIC = 3727.69

# 2, 0, 2
NO.arima202 <- arima(e.ts.NO, order = c(2,0,2), include.mean = FALSE)
summary(NO.arima202)
# AIC = 3729.69

# 2, 0, 3
NO.arima203 <- arima(e.ts.NO, order = c(2,0,3), include.mean = FALSE)
summary(NO.arima203)
# AIC = 3712.8

# 2, 0, 4
NO.arima204 <- arima(e.ts.NO, order = c(2,0,4), include.mean = FALSE)
summary(NO.arima204)
# AIC = 3714.6

# 2, 1, 1
NO.arima211 <- arima(e.ts.NO, order = c(2,1,1), include.mean = FALSE)
summary(NO.arima211)
# AIC = 3725.19

# 2, 1, 2
NO.arima212 <- arima(e.ts.NO, order = c(2,1,2), include.mean = FALSE)
summary(NO.arima212)
# AIC = 3726.05

# 2, 1, 3
NO.arima213 <- arima(e.ts.NO, order = c(2,1,3), include.mean = FALSE)
summary(NO.arima213)
# AIC = 3728.05

# 2, 1, 4
NO.arima214 <- arima(e.ts.NO, order = c(2,1,4), include.mean = FALSE)
summary(NO.arima214)
# AIC = 3711.28

# 3, 0, 1
NO.arima301 <- arima(e.ts.NO, order = c(3,0,1), include.mean = FALSE)
summary(NO.arima301)
# AIC = 3729.69

# 3, 0, 2
NO.arima302 <- arima(e.ts.NO, order = c(3,0,2), include.mean = FALSE)
summary(NO.arima302)
# AIC = 3698.16
# second lowest

# 3, 0, 3
NO.arima303 <- arima(e.ts.NO, order = c(3,0,3), include.mean = FALSE)
summary(NO.arima303)
# AIC = 3713.87

# 3, 0, 4
NO.arima304 <- arima(e.ts.NO, order = c(3,0,4), include.mean = FALSE)
summary(NO.arima304)
# NaNs produced

# 3, 1, 1
NO.arima311 <- arima(e.ts.NO, order = c(3,1,1), include.mean = FALSE)
summary(NO.arima311)
# AIC = 3727.19

# 3, 1, 2
NO.arima312 <- arima(e.ts.NO, order = c(3,1,2), include.mean = FALSE)
summary(NO.arima312)
# AIC = 3728.04

# 3, 1, 3
NO.arima313 <- arima(e.ts.NO, order = c(3,1,3), include.mean = FALSE)
summary(NO.arima313)
# AIC = 3730.01

# 3, 1, 4
NO.arima314 <- arima(e.ts.NO, order = c(3,1,4), include.mean = FALSE)
summary(NO.arima314)
# AIC = 3708.73
```
Based on AIC, the two best models are the ARIMA(1,0,4) and ARIMA(3,0,2) models.

After testing the possible values of p, d, and q that we identified, we also used the auto.arima function to generate another model.
```{r}
# auto.arima model
NO.residuals.auto <- auto.arima(e.ts.NO, approximation = FALSE)

# summary
summary(NO.residuals.auto)
```
The ARIMA model is a 1,0,0 model. This means that there are autoregressive terms, where p = 1, but no moving average terms, since q = 0. Also, d = 0, meaning that the time series is stationary, which is a key assumption to modeling the residuals. The AIC for this model is 3725.46.

### Diagnostics
```{r}
tsdiag(NO.arima104, gof.lag = 20)
tsdiag(NO.arima302, gof.lag = 20)
tsdiag(NO.residuals.auto, gof.lag = 20)
```
The model that performs the best in diagnostics is the ARIMA(1,0,4) model. It has the same number of points with p-values above the dashed line as the ARIMA(3,0,2) model, but the points are higher. Both models performed significantly better than the auto-generated model, meaning that that model was adequate up to fewer lags. The two models we chose the parameters for are adequate for up to 11 lags, but the auto-generated model is adequate for about 6 lags.

### Choose Model for Residuals
```{r}
NO.residuals <- NO.arima104
```
This model has the lowest AIC and also the best diagnostic plot of the models considered.

## Final Model
The final model includes a trend and seasonality, using 9 different periods, two of which are the averages of 4 similar periods each. The ARIMA model of the residuals is a 3,1,11 model.

### Create the final Model
```{r}

```

## Diagnostics
The residuals of the trend and seasonality linear model appear relatively normal, from the QQ plot. There are no points with high Cook's distances. The residuals vs. fitted and scale-location plots have minor problems; they could have more even spread and a mean even closer to zero, but overall they look good. In the future, another model could be identified that performs even better in regard to these diagnostics.  
In the diagnostic plot for the model of the residuals, the p-value for the Ljung-Box stastic is above the dashed line for 15 of the 20 lags, meaning that the model of the residuals is adequate for up to 15 lags. A future model could work to extend the model adequacy to all 20 lags of the plot.







The final model includes a trend and seasonality, using 9 different periods, two of which are the averages of 4 similar periods each. The ARIMA model of the residuals is a 1,0,4 model.

### Diagnostics
The residuals of the trend and seasonality linear model appear relatively normal, from the QQ plot. There are no points with high Cook's distances. The residuals vs. fitted and scale-location plots have minor problems; they could have more even spread, but overall they look good and indicate acceptable fit. 
In the diagnostic plot for the model of the residuals, the p-value for the Ljung-Box stastic is above the dashed line for 11 of the 20 lags, meaning that the model of the residuals is adequate for up to 11 lags. A future model could work to extend the model adequacy to all 20 lags of the plot.


\pagebreak
# Multivariate Time Series
## Seasonality and Trends
We used the same linear models for the seasonality and trends that we discovered in our analysis of the univariate time series for CO and NO2. See above for how we modeled seasonal components and trends to produce these linear models.  
The ARMA models for the residuals of both time series use d = 0, meaning that both meet the stationarity assumption without taking the first differences.

## Autoregressive and Moving Average Terms
In our univariate models, the residuals for CO were modeled with an ARIMA(2,0,1) model and the residuals for NO2 were modeled with an ARIMA(1,0,4) model. There were autoregressive and moving average terms in both cases. Since there were different p and q values used to model the residuals for each time series, it is difficult to use the ACF and PACF to determine values for p and q for the multivariate model. Because of this, we will test models with p from 1 to 2 and q from 0 to 4 to determine the best VARMA model.

## Models




# p from 4 to 7, q from 9 to 11
```{r}
# all residuals together
allResiduals <- data.frame(CO.lm$residuals, NO.lm$residuals)

# Build VARMA models

# p from 1 to 2, q from 0 to 4
AICmatrix <- matrix(NA, 2, 5)
for(p in 1:2) {
  for(q in 0:4) {
    varma.model <- VARMACpp(allResiduals, p=p, q=q, include.mean=F)
    AICmatrix[p,q+1] <- varma.model$aic
  }
}
```



\pagebreak
## Model Comparison
### Metrics
```{r}
# get AIC matrix
AICmatrix
# AICmatrix.sorted <- sort(AICmatrix, decreasing = F, index.return = T)
# AICmatrix.sorted
```
The two models with the lowest AIC values are VARMA(2,2) and VARMA(1,0) with an AIC of 7.098223 and 7.103681, respectively.

### Diagnostics
```{r}
# model with lowest AIC
varma.model1 <- VARMACpp(allResiduals, p=2, q=2, include.mean=F)

# model with second lowest AIC
varma.model2 <- VARMACpp(allResiduals, p=1, q=0, include.mean=F)

# diagnostics for model1
MTSdiag(varma.model1)

# diagnostics for model2
MTSdiag(varma.model2)
```
The VARMA(2,2) model performs best in the diagnostics. The model is adequate for 11 lags, as the p-values for the Ljung-Box statistic are above the dashed line for these points. The second model we tested had three Ljung-Box statistics at lags 2, 3, and 4 with a p-value above the dashed line.

## Final Model
```{r, include = FALSE}
varma.model <- VARMACpp(allResiduals, p=2, q=2, include.mean=F)
```
We did not include the chunk that actually ran the code to create the final model, so that it would not print the output. The commented code below is the code we ran.
```{r}
# varma.model <- VARMACpp(allResiduals, p=2, q=2, include.mean=F)
```
The final model was chosen as the VARMA(2,2) model, because it has the lowest AIC and performed the best in the diagnostic plot.

### Diagnostics
The model is adequate for up to 11 lags, based on the diagnostic plot. Future work could attempt to produce a model adequate for more lags, but we feel that this is acceptable performance from the model we have chosen.


\pagebreak
# Simulation from Univariate CO Model
```{r}
# CO ARIMA model is 2,0,1

# simulate residuals
set.seed(1)
CO.uni.sim <- arima.sim(n = 365, list(ar = c(CO.residuals$coef[1], 
                                             CO.residuals$coef[2]), 
                                      ma = c(CO.residuals$coef[3])), 
                                      sd = sqrt(CO.residuals$sigma2))

# the next time variable- simulate the next 365 days
next.time.time <- c(1:(365))
next.time <- data.frame(time.CO = next.time.time)

CO.mean <- predict(CO.lm, newdata = next.time)

# make time series
CO.uni.sim.ts <- ts(CO.uni.sim + CO.mean)
<<<<<<< HEAD
=======

plot(CO.uni.sim + CO.mean, main = "CO Univariate Simulation")
>>>>>>> 13f1fd4bd6a55d0bf6d33be4e18f8e085a211e15
```
This is the plot of the simulation.

\pagebreak
## Visualization
```{r}
# plot simulated values with observations
plot(CO.ts, main = "Simulation from Univariate CO Model", col = "black", ylim = c(-1,12))
lines(CO.uni.sim.ts, col = "red")
legend(0, 12.5, legend = c("Time Series Data", "Simulation"), col = c("black", "red"), lwd = 1)
```
The simulation values appear to be similar to the time series data, though they are slightly larger than the time series before t = 200.

## Trend
```{r}
# linear model for simulation
CO.sim.lm <- lm(CO.uni.sim.ts ~ next.time.time)
summary(CO.sim.lm)
summary(CO.lm.trend)
```
We made a linear model for the simulation with time as a predictor to determine if there was a trend to the data. The model was significant, meaning that there is a trend to the simulation. The estimated coefficient value was 0.0032 for the simulation and 0.0029 for the original time series. These coefficients are very close, so the simulation was able to accurately reproduce the trend of the original time series. 

\pagebreak
## Seasonality
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')
pg.CO.uni.sim <- spec.pgram(CO.uni.sim.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
The periodograms of the original observations and simulation look similar. They have similar peak locations and magnitudes, especially at the lower end of the frequencies. The simulation was able to closely reproduce the seasonality of the time series.

\pagebreak
## Mean and Variance
```{r}
# mean of observations
mean(CO.ts)

# mean of simulation
mean(CO.uni.sim.ts)

# variance of observations
var(CO.ts)

# variance of simulation
var(CO.uni.sim.ts)
```
The mean of the original time series is 4.36, and the mean of the simulation is 4.34. The means are very close together, which was apparent from the plot of both the time series and simulation together.  
The variance of the original time series is 3.62, and the variance of the simulation is 3.499. The variances are also similar.

## Auto-Correlation
```{r}
# ACF of observations
acf(CO.ts)

# ACF of simulation
acf(CO.uni.sim.ts)
```
The simulation got close to reproducing the ACF of the time series. They both cutoff and become significant again and show somewhat sinusoidal behavior.

\pagebreak
```{r}
# PACF of observations
pacf(CO.ts)

# PACF of simulation
pacf(CO.uni.sim.ts)
```
The ACFs look more similar, though the PACF of the time series and simulation are close as well. Both cutoff and become significant again, and both are significant for the first lag but not for the second.

From comparing the ACF and PACF of the time series and simulation, the simulation was able to reproduce the autocorrelation of the time series.


\pagebreak
# Simulation from Univariate NO2 Model
```{r}
# NO2 ARIMA model is 1,0,4

# simulate residuals
set.seed(1)
NO.uni.sim <- arima.sim(n = 365, list(ar = c(NO.residuals$coef[1]), 
                                      ma = c(NO.residuals$coef[2],
                                             NO.residuals$coef[3],
                                             NO.residuals$coef[4],
                                             NO.residuals$coef[5])), 
                                      sd = sqrt(NO.residuals$sigma2))

# the next time variable- simulate the next 365 days
next.time.NO <- data.frame(time.NO = next.time.time)

NO.mean <- predict(NO.lm, newdata = next.time.NO)

# make time series
NO.uni.sim.ts <- ts(NO.uni.sim + NO.mean)

plot(NO.uni.sim + NO.mean, main = "NO2 Univariate Simulation")
```
This is the plot of the simulation.

\pagebreak
## Visualization
```{r}
# plot simulated values with observations
plot(NO.ts, main = "Simulation from Univariate NO2 Model", col = "black", ylim = c(0,350))
lines(NO.uni.sim.ts, col = "red")
legend(0, 350, legend = c("Time Series Data", "Simulation"), col = c("black", "red"), lwd = 1)
```
The simulation values appear similar to the time series values, especially in the trend of the data.

## Trend
```{r}
# linear model for simulation
NO.sim.lm <- lm(NO.uni.sim.ts ~ next.time.time)
summary(NO.sim.lm)
summary(NO.lm.trend)
```
We made a linear model for the simulation with time as a predictor to determine if there was a trend to the data. The model was significant, meaning that there is a trend to the simulation. The estimated coefficient value was 0.262 for the simulation and 0.256 for the original time series. These coefficients are very close, so the simulation was able to accurately reproduce the trend of the original time series. 

\pagebreak
## Seasonality
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.NO <- spec.pgram(NO.ts,spans=9, demean=T, log='no')
pg.NO.uni.sim <- spec.pgram(NO.uni.sim.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
The periodograms of the original observations and simulation look similar, but the periodogram for the simulation appears to have different peaks in the frequency range of 0.05 to 0.2. The simulation was able to somewhat closely reproduce the seasonality of the time series.

\pagebreak
## Mean and Variance
```{r}
# mean of observations
mean(NO.ts)

# mean of simulation
mean(NO.uni.sim.ts)

# variance of observations
var(NO.ts)

# variance of simulation
var(NO.uni.sim.ts)
```
The mean of the original time series is 164.53, and the mean of the simulation is 162.78. The means are very close together, which was apparent from the plot of both the time series and simulation together.  
The variance of the original time series is 2657.722, and the variance of the simulation is 2619.679. The variances are also similar, with the simulation being a little lower.

## Auto-Correlation
```{r}
# ACF of observations
acf(NO.ts)

# ACF of simulation
acf(NO.uni.sim.ts)
```
The ACFs look very similar; they are both significant for all 25 lags in view on the plot and have some sinusoidal behavior. 

\pagebreak
```{r}
# PACF of observations
pacf(CO.ts)

# PACF of simulation
pacf(CO.uni.sim.ts)
```
The ACFs look more similar, though the PACF of the time series and simulation are close as well. Both cutoff and become significant again, and both are significant for the first lag but not for the second.

From comparing the ACF and PACF of the time series and simulation, the simulation was able to reproduce the autocorrelation of the time series.


\pagebreak
# Simulation from Multivariate Model
```{r}
# VARMA model is 2,2

# simulate residuals
set.seed(1)
multi.sim <- VARMAsim(365, phi = varma.model$Phi,
                           theta = varma.model$Theta,
                           sigma = varma.model$Sigma)

# make time series
multi.sim.CO.ts <- ts(multi.sim$series[,1] + CO.mean)
multi.sim.NO.ts <- ts(multi.sim$series[,2] + NO.mean)
plot(multi.sim.CO.ts, main = "CO Multivariate Simulation")
plot(multi.sim.NO.ts, main = "NO2 Multivariate Simulation")
```
These are the plots of the simulations.

\pagebreak
## Visualization- CO
```{r}
# plot simulated values with observations
plot(CO.ts, main = "Simulation from Multivariate Model for CO", col = "black", ylim = c(-1,12))
lines(multi.sim.CO.ts, col = "red")
legend(0, 12.5, legend = c("Time Series Data", "Simulation"), col = c("black", "red"), lwd = 1)
```
The simulation values appear to be similar to the time series data.

\pagebreak
## Visualization- NO2
```{r}
# plot simulated values with observations
plot(NO.ts, main = "Simulation from Multivariate Model for NO2", col = "black", ylim = c(0,350))
lines(multi.sim.NO.ts, col = "red")
legend(0, 340, legend = c("Time Series Data", "Simulation"), col = c("black", "red"), lwd = 1)
```
The simulation values appear to be similar to the time series data.

## Trend- CO
```{r}
# linear model for simulation
CO.multi.sim.lm <- lm(multi.sim.CO.ts ~ next.time.time)
summary(CO.multi.sim.lm)
summary(CO.lm.trend)
```
We made a linear model for the simulation with time as a predictor to determine if there was a trend to the data. The model was significant, meaning that there is a trend to the simulation. The estimated coefficient value was 0.0033 for the simulation and 0.0029 for the original time series. These coefficients are very close, so the simulation was able to accurately reproduce the trend of the original time series. 

## Trend- NO2
```{r}
# linear model for simulation
NO.multi.sim.lm <- lm(multi.sim.NO.ts ~ next.time.time)
summary(NO.multi.sim.lm)
summary(NO.lm.trend)
```
We made a linear model for the simulation with time as a predictor to determine if there was a trend to the data. The model was significant, meaning that there is a trend to the simulation. The estimated coefficient value was 0.255 for the simulation and 0.256 for the original time series. These coefficients are very close, so the simulation was able to accurately reproduce the trend of the original time series. 

\pagebreak
## Seasonality- CO
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')
pg.CO.multi.sim <- spec.pgram(multi.sim.CO.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
The periodograms of the original observations and simulation are not very similar. There are fewer peaks in the simulation periodogram.

\pagebreak
## Seasonality- NO2
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.NO <- spec.pgram(NO.ts,spans=9,demean=T,log='no')
pg.NO.multi.sim <- spec.pgram(multi.sim.NO.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
The periodograms of the original observations and simulation are similar. There are similar peaks in similar locations in both periodograms.

\pagebreak
## Mean and Variance
```{r}
# mean of observations- CO
mean(CO.ts)

# mean of simulation- CO
mean(multi.sim.CO.ts)

# mean of observations- NO2
mean(NO.ts)

# mean of simulation- NO2
mean(multi.sim.NO.ts)

# variance of observations- CO
var(CO.ts)

# variance of simulation- CO
var(multi.sim.CO.ts)

# variance of observations- NO2
var(NO.ts)

# variance of simulation- NO2
var(multi.sim.NO.ts)
```
**CO: **The mean of the original time series is 4.36, and the mean of the simulation is 4.24. The means are very close together, which was apparent from the plot of both the time series and simulation together.  
The variance of the original time series is 3.62, and the variance of the simulation is 3.59. The variances are also similar.

**NO2: **The mean of the original time series is 164.53, and the mean of the simulation is 160.64. The means are close together, which was apparent from the plot of both the time series and simulation together.  
The variance of the original time series is 2657.722, and the variance of the simulation is 2499.248. The variances are also similar.

\pagebreak
## Auto-Correlation- CO
```{r}
# ACF of observations
acf(CO.ts)

# ACF of simulation
acf(multi.sim.CO.ts)
```
The simulation got close to reproducing the ACF of the time series, though the ACF of the simulation is significant for all of the lags in view and the ACF of the time series cuts off and becomes significant again. Both have some sinusoidal behavior.

\pagebreak
```{r}
# PACF of observations
pacf(CO.ts)

# PACF of simulation
pacf(multi.sim.CO.ts)
```
The PACF of the simulation does not match the PACF of the time series. The PACF of the simulation cuts off after 5 lags, but the PACF of the original time series cuts off after 1 lag and then becomes significant again.

From comparing the ACF and PACF of the time series and simulation, the simulation was somewhat able to reproduce the autocorrelation of the time series.

\pagebreak
## Auto-Correlation- NO2
```{r}
# ACF of observations
acf(NO.ts)

# ACF of simulation
acf(multi.sim.NO.ts)
```
The simulation got very close to reproducing the ACF of the time series. They both are significant for all lags in view on the plot and display some sinusoidal behavior.

\pagebreak
```{r}
# PACF of observations
pacf(NO.ts)

# PACF of simulation
pacf(multi.sim.NO.ts)
```
The ACFs look more similar. The PACF shows more significance at the smaller lags than the original time series.

From comparing the ACF and PACF of the time series and simulation, the simulation was somewhat able to reproduce the autocorrelation of the time series.

\pagebreak
# Cross-Correlation
## Cross-Correlation of Time Series
```{r}
cor(CO.ts, NO.ts)
#correlation = 0.608
```

## Cross-Correlation of Univariate Models
```{r}
cor(CO.uni.sim.ts, NO.uni.sim.ts)
#correlation = 0.126
```

## Cross-Correlation of Multivariate Models
```{r}
cor(multi.sim.CO.ts, multi.sim.NO.ts)
#correlation = 0.560
```
The cross-correlation for the original time series is 0.608. The cross-correlation for the univariate models is much lower, at 0.126. The cross-correlation for the multivariate models is 0.560, which is closer to the original value. Using a multivariate model better preserved the correlation between the time series.

\pagebreak
#### Bonus 

# Create forecasts - worry about this later
Forecast for CO 
```{r}
nextweek.time.time <- c(1:(7))
nextweek.time <- data.frame(time.CO = nextweek.time.time)

E_Y.pred.CO <- predict(CO.lm, newdata=nextweek.time)

# Bonus: Forecasting
### Forecast for CO 
```{r}
nextweek.time.time <- c(1:(7))
nextweek.time.CO <- data.frame(time.CO = nextweek.time.time)

E_Y.pred.CO <- predict(CO.lm, newdata = nextweek.time.CO)
e_t.pred.CO <- forecast(CO.residuals, h=7)
CO.forecast <- E_Y.pred.CO + e_t.pred.CO$mean
```


### Forecast for NO2 
```{r}
# option one
E_Y.pred.NO <- predict(NO.lm, newdata=test_c)
air.test$NO2.GT.
E_Y.pred.NO
## Forecast for NO2 


# option two
nextweek.time.NO <- data.frame(time.NO = nextweek.time.time)
E_Y.pred.NO <- predict(NO.lm, newdata = nextweek.time.NO)
e_t.pred.NO <- forecast(NO.residuals, h=7)
e_t.pred.NO
NO.forecast <- E_Y.pred.NO + e_t.pred.NO$mean
```

### Forecast for CO and NO2 (Multivariate Model)
```{r}
<<<<<<< HEAD
CO.NO.forecast <- VARMApred(CO.NO.residuals, h=7)
=======
CO.NO.forecast <- VARMApred(varma.model, h=7)
>>>>>>> 13f1fd4bd6a55d0bf6d33be4e18f8e085a211e15

e_t.pred.CO.multi <- CO.NO.forecast$pred[,1]
e_t.pred.CO.lower <- CO.NO.forecast$pred[,1] - 1.96*CO.NO.forecast$se.err[,1]
e_t.pred.CO.upper <- CO.NO.forecast$pred[,1] + 1.96*CO.NO.forecast$se.err[,1]
CO.multi.forecast<- E_Y.pred.CO + e_t.pred.CO.multi

e_t.pred.NO.multi <- CO.NO.forecast$pred[,2]
e_t.pred.NO.lower <- CO.NO.forecast$pred[,2] - 1.96*CO.NO.forecast$se.err[,2]
e_t.pred.NO.upper <- CO.NO.forecast$pred[,2] + 1.96*CO.NO.forecast$se.err[,2]
NO.multi.forecast <- E_Y.pred.NO + e_t.pred.NO.multi
```

\pagebreak
## Comparison based on MSE 
```{r}
#CO MSE
mean((CO.forecast-air.test$CO.GT.)^2)
# MSE = 4.71

#NO2 MSE
mean((NO.forecast-air.test$NO2.GT.)^2)
# MSE = 542.95

#CO and NO2 MSE - Multivariate
mean((CO.multi.forecast-air.test$CO.GT.)^2)
# MSE = 4.40
mean((NO.multi.forecast-air.test$NO2.GT.)^2)
# MSE = 543.25
```
The MSE for the CO forecast from the univariate model is higher than that from the multivariate model which implies that the multivariate model models the residuals of CO better. Conversely, the MSE for the univariate model for NO2 is smaller than that from the multivariate model which implies that the univariate model does a better job of modeling the residuals of NO2. Despite all this, the MSE between the univariate and multivariate models are very close. 

\pagebreak
## Visual Comparison
### Forecast from CO Univariate Model
```{r}
# Plot actual values and predicted values
plot(ts(air.test$CO.GT.),type='o', ylim = c(0,10))
plot(ts(air.test$CO.GT.),type='o',ylim=c(0,10))
lines(ts(CO.forecast),col='red',type='o')
lines(1:7, E_Y.pred.CO + e_t.pred.CO$lower[,2], col = "red", lty = "dashed")
lines(1:7, E_Y.pred.CO + e_t.pred.CO$upper[,2], col = "red", lty = "dashed")

legend(2,2, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red")) 
```
The predicted values are higher than the actual values for all but one point. There are two actual values that lie outside of the confidence interval of the prediction.

\pagebreak
### Forecast from NO2 Univariate Model
```{r}
# Plot actual values and predicted values
plot(ts(air.test$NO2.GT.),type='o',ylim=c(50,275))
lines(ts(NO.forecast),col='red',type='o')
lines(1:6, E_Y.pred.NO + e_t.pred.NO$lower[,2], col = "red", lty = "dashed")
lines(1:6, E_Y.pred.NO + e_t.pred.NO$upper[,2], col = "red", lty = "dashed")
legend(2,1, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red")) 
lines(1:7, E_Y.pred.NO + e_t.pred.NO$lower[,2], col = "red", lty = "dashed")
lines(1:7, E_Y.pred.NO + e_t.pred.NO$upper[,2], col = "red", lty = "dashed")
legend(2,107, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red")) 
```
All of the actual values are within the bounds of the confidence interval of the predictions. The actual valyes are higher than the predictions for 5 out of the 7 points.

\pagebreak
### Forecast from Multivariate Model 
```{r}
<<<<<<< HEAD
#Multi Plot 
par(mfrow=c(1,2))
=======
>>>>>>> 13f1fd4bd6a55d0bf6d33be4e18f8e085a211e15
# CO forecasts
plot(ts(air.test$CO.GT.),type='o', ylim = c(0,10), main = "CO Forecast")
lines(ts(CO.multi.forecast),col='red',type='o')
lines(1:7, E_Y.pred.CO + e_t.pred.CO.lower, col = "red", lty = "dashed")
lines(1:7, E_Y.pred.CO + e_t.pred.CO.upper, col = "red", lty = "dashed")
legend(2,2, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red"))
```
\pagebreak
```{r}
#NO forecasts
plot(ts(air.test$NO2.GT.),type='o',ylim = c(50,275),main = "NO2 Forecast")
lines(ts(NO.multi.forecast),col='red',type='o')
lines(1:7, E_Y.pred.NO + e_t.pred.NO.lower, col = "red", lty = "dashed")
lines(1:7, E_Y.pred.NO + e_t.pred.NO.upper, col = "red", lty = "dashed")
legend(2,107, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red"))
```
Similar to the univariate model's forecast, the multivariate model's forecast for CO predicts that all points are higher than their actual values. There is only one point that is outside the confidence interval and it appears as if it is only just barely outside the interval. 

Much like the univariate model, the actual values for NO2 all lie within the multivariate model's confidence interval. 2 predicted points are less than their predicted values and 5 points are greater than their predicted values. 