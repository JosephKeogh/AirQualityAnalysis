---
title: "Project 2"
author: "Camryn Burley, Anna Haikl, and Joseph Keogh"
date: "12-4-19"
abstract: "On our honor as students, we have neither given nor received aid on this assignment."
output:
  pdf_dCOument: default
  html_dCOument: default
---

<<<<<<< HEAD
```{r setup, include=FALSE}
#=======
#Anna's Setup
#=======
require("knitr")
datadir <- "/Users/annahaikl/Desktop/UVA/FALL 2019/4021/DATA/Air Quality"
sourcedir <-"/Users/annahaikl/Desktop/UVA/FALL 2019/4021/CODE"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
```

```{r setup, include = FALSE}
# Camryn Set Up
require("knitr")
datadir <- "/Users/camrynburley/Desktop/UVA/SYS4021/Data/AirQuality"
sourcedir <- "/Users/camrynburley/Desktop/UVA/SYS4021/RCode"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
```

# Load Data and Impute Missing Values
```{r, warning=FALSE}
setwd(datadir)

airquality = read.csv('AirQualityUCI.csv')

# replace -200 with NA
airquality[airquality == -200] <- NA

# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
  airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}

setwd(sourcedir)

# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]

# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', 
             ga.control=list(formula=paste(names(AQdata)[c(1:3)],'~ns(t,2)')))

# set airquality to imputed data
AQdata <- i$filled.dataset

# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
```

# Create Testing and Training Data
```{r}
# the index to split the data on
separationIndex <- nrow(dailyAQ)-6

# split the data
air.train <- dailyAQ[1:separationIndex-1,]
air.test <- dailyAQ[separationIndex:nrow(dailyAQ),]

# making sure no data was duplicated or lost
a <- nrow(dailyAQ)
b <- nrow(air.train)
c <- nrow(air.test)

a
b
c
```

# Data Summary
```{r}
summary(air.train)
```
The data is from March 2004 through April 2005. We are modeling the ambient daily maximum carbon monoxide (CO) and nitrogen dioxide (NO2) concentrations. 

# Univariate Time Series for CO
## Visualize the Data
```{r}
# create time series
CO.ts <- ts(air.train$CO.GT.)

# visualize raw data
plot(CO.ts)
```
There is no extremely obvious trend from the plot of the time series. There may be some seasonality, but we are unsure as of now if this fluctuation is from seasonality or if it is random.

```{r}
# periodogram
pg.CO <- spec.pgram(CO.ts,spans=9,demean=T,log='no')
```
Based on the periodogram, there are multiple possibilities for the period of a seasonal component. There are a few spikes, each of which indicate a possible frequency/period to explain the seasonality of the data. We predict that if the seasonality is significant in the model, it will be based on a complex wave. 

```{r}
# ACF and PACF
acf(CO.ts)
pacf(CO.ts)
```
The ACF is approximately sinusoidal. The PACF does not cut off after a certain number of lags and has some sinusoidal behavior. This indicates that there may be some autoregressive and moving average components in our model of the residuals.

## Seasonality
### Finding Potential Periods
```{r}
# sort the frequencies based on influence
sorted.spec <- sort(pg.CO$spec, decreasing=T, index.return=T)

# convert to periods
sorted.omegas <- pg.CO$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.CO$freq[sorted.spec$ix]

# the cutoff for influential
CO.pg.cutoff <- 5

# the top periods
print('top periods')
sorted.Ts[1:CO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas[1:CO.pg.cutoff]

# visual
CO.pg.box <- boxplot(sorted.Ts[1:CO.pg.cutoff], main="Period Boxplot")

# the average influential period
print('mean of top periods')
CO.pg.box.mean <- CO.pg.box$stats[3]
print(CO.pg.box.mean)

# plot top periods
plot(sorted.Ts[1:CO.pg.cutoff], main = "Top Periods")
```
We found the frequencies of the largest spikes in the periodogram graph and converted them to periods by taking 1/the frequency. The five largest spikes correspond to periods of 384, 192, 128, 96, and 76.8 days. We considered these our "top" choices for periods to explain seasonality.  
We are concerned that the reason we are seeing a period of 384 days is because this is close to the length of the data set and not because there is actual correlation between data values collected 384 days apart. We will investigate whether or not to use this period in the following sections.

### Create Model with Potential Periods
To begin, we made a model without the 384 day period but that included the other four periods.
```{r}
# assign potential periods to variables
CO.p1 <- sorted.Ts[1]
CO.p2 <- sorted.Ts[2]
CO.p3 <- sorted.Ts[3]
CO.p4 <- sorted.Ts[4]
CO.p5 <- sorted.Ts[5]

# CO.p1
# CO.p2
# CO.p3
# CO.p4
# CO.p5

# create time variable
time.CO<-c(1:length(CO.ts))

# model
CO.lm.top4 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top4)
```
This model will be compared to a model that only uses the first "important" period (i.e. the period associated with the largest spike in the periodogram, with the exception of the one corresponding to 384 days).

### Compare Larger Model with Model with Only First Important Period
```{r}
# actual model
CO.lm.top1 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p2) + cos(2*pi*time.CO/CO.p2))

# model summary
summary(CO.lm.top1)

# anova
anova(CO.lm.top1, CO.lm.top4)
```
The p-value of the partial F-test is 0.0024, which is significant at the 0.05 level. We reject the null hypothesis, which means that the larger model contains at least one coefficient, not shared with the smaller model, that is significant. The larger model is better at explaining variability.

### Create Model with All Identified Periods
```{r}
# actual model
CO.lm.top5 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4)+
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5))

# model summary
summary(CO.lm.top5)

# compare with smaller model
anova(CO.lm.top4, CO.lm.top5)
```
We created the model that used all five periods identified from the periodogram. We compared it to the model without the 384-day period using a partial F test. The test is significant at the 0.05 level, which means there is significant evidence to use the larger model. We will use the model with all five periods to explain seasonality in further analysis.

### Visual Inspection of Model
```{r}
plot(CO.ts)
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top5$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top5$fitted.values, col = "red")
```
We plotted the fitted values of the model in red over the graph of the time series data. We plotted the entire time series and also zoomed in to see t = [0, 100] and t = [100, 200]. The model follows the general trend of the data, but there are no small fluctuations, of which the data has many. We may need to add a term with a smaller period in order to capture these smaller fluctuations.

### Explore Adding Higher Frequency Components
```{r}
# visual for frequency
plot(sorted.omegas, xlim=c(0,10))

# visual for periods
plot(sorted.Ts, xlim=c(0,30))

# look at the 6th through 10th most influencial periods
next.low.period <- boxplot(sorted.Ts[6:10])$stats[3]
next.low.period
```
The average of the periods associated with the next five highest spikes of the periodogram is about 7 days. A period of around 7 days makes sense to us, as CO production could be vary weekly from people working and commuting.

### Add New Period to Model
We made a new model with all five periods in our previous model and the addition of the new period around 7 days.
```{r}
CO.p6 <- next.low.period

# model
CO.lm.top6 <- lm(CO.ts ~ sin(2*pi*time.CO/CO.p1) + 
                         cos(2*pi*time.CO/CO.p1) +
                         sin(2*pi*time.CO/CO.p2) + 
                         cos(2*pi*time.CO/CO.p2) +
                         sin(2*pi*time.CO/CO.p3) + 
                         cos(2*pi*time.CO/CO.p3) +
                         sin(2*pi*time.CO/CO.p4) + 
                         cos(2*pi*time.CO/CO.p4) +
                         sin(2*pi*time.CO/CO.p5) + 
                         cos(2*pi*time.CO/CO.p5) +
                         sin(2*pi*time.CO/CO.p6) + 
                         cos(2*pi*time.CO/CO.p6))

# model summary
summary(CO.lm.top6)

# visual inspection
plot(CO.ts)
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(CO.lm.top6$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(CO.lm.top6$fitted.values, col = "red")
```
Upon visually inspecting this new model, we see smaller fluctuations, which we wanted. However, we do see that the peaks of the smaller waves do not consistently match up with where the data has a peak, based on the zoomed in graphs.

### Comparison of Models
```{r}
anova(CO.lm.top5, CO.lm.top6)
```
The p-value is 0.2364, which means we fail to reject the null hypothesis. The smaller model is better in this case, as the coefficients in the larger model (not shared with the smaller model) were not found to be significant. We will use the model with the five periods.

### Choose Seasonal Model
```{r}
CO.lm.seasonal <- CO.lm.top5
```
We have chosen the model with the top five identified periods to explain seasonality, as it has been shown to be better than the model with only the 192-day period and the model which also included a 7-day period.

## Trend
### Model Time Series Based on Time
```{r}
# model
CO.lm.trend <- lm(CO.ts ~ time.CO)

# summary analysis
summary(CO.lm.trend)
```
The p-value is 0.00097 so there is  a significant trend in the data.

### Visualize Trend
```{r}
plot(CO.ts)
abline(CO.lm.trend, col='red')
```

### Model Trend and Seasonality Together
```{r}
# model
CO.seasonal.trend <- lm(CO.ts ~ CO.lm.trend$effects + CO.lm.seasonal$effects)

# visualize
model <- CO.seasonal.trend
plot(CO.ts)
lines(model$fitted.values, col = "red")

plot(CO.ts, xlim=c(0,100))
lines(model$fitted.values, col = "red")

plot(CO.ts, xlim=c(100,200))
lines(model$fitted.values, col = "red")
```
Based on visual inspection, this model, including both trend and seasonality, is pretty good. It is especially good at modeling the data at the beginning of the time series. After that, while the peaks are not of the same magnitude as those of the data, they occur at relatively the same x-value. 

## Model Residuals
### ARIMA model
Based on the ACF and PACF (shown earlier), we predict there will be autoregressive and moving average terms. We used the auto.arima function to determine if this was correct and to find the p and q values.
```{r}
# get residuals
e.ts.CO <-ts(CO.seasonal.trend$residuals)

# arima model
CO.residuals.auto <- auto.arima(e.ts.CO)

# summary
summary(CO.residuals.auto)
```
The ARIMA model is a 5,1,4 model. This means that there are autoregressive and moving average terms, where p = 5 and q = 4. Also, d = 1, meaning that the first differences were used to ensure stationarity, which is a key assumption to modeling the residuals.

### Choose Model for Residuals
```{r}
CO.residuals <- CO.residuals.auto
```

## Model Assessment 
do for 5 and 6 period trend/seasonality models and again for ARIMA models (need to predict values for p,d,q to compare to auto.arima)
### Metrics
compare models based on adjusted R2 and/or AIC
### Diagnostics
diagnostics of linear models of trends + seasonality and ARIMA models of residuals
### Forecasting
compare models based on MSE

## Final Model
The final model includes a trend and seasonality, using 5 different periods. The ARIMA model of the residuals is a 5,1,4 model.

## Diagnostics
what problems remain in the diagnostics of the selected model?


# Univariate Time Series for NO2
## Visualize the Data
```{r}
# create time series
NO.ts <- ts(air.train$NO2.GT.)

# visualize raw data
plot(NO.ts)

# periodogram
pg.NO <- spec.pgram(NO.ts,spans=9,demean=T,log='no')

# acf and pacf
acf(NO.ts)
pacf(NO.ts)
```

No obvious trend or seasonality based on raw data

based on periodogram there may be some seasonlity, but it is going to be based on complex waves

Determine if there is seasonality in the data
```{r}
# sort the frequencies based on influence
sorted.spec.NO <- sort(pg.NO$spec, decreasing=T, index.return=T)

# convert to periods
sorted.omegas.NO <- pg.NO$freq[sorted.spec.NO$ix]
sorted.Ts.NO <- 1/pg.NO$freq[sorted.spec.NO$ix]

plot(sorted.Ts.NO, xlim = c(1,20))

# the cutoff for influencial
NO.pg.cutoff <- 15


# the top periods
print('top periods')
sorted.Ts.NO[1:NO.pg.cutoff]

# top frequencies
## to double check that this makes sense based on periodogram
print('top frequencies')
sorted.omegas.NO[1:NO.pg.cutoff]

# visual
NO.pg.box <- boxplot(sorted.Ts.NO[1:NO.pg.cutoff], main="Period Boxplot")

# the average influencial period
print('mean of top periods')
NO.pg.box.mean <- NO.pg.box$stats[3]
print(NO.pg.box.mean)
```

The average influencial period can be interpreted as on average the seasons have a period of 48 days

The top 15 periods range from 6.62 to 384 days

The top 15 frequencies range from 0.0026 to 0.15
    
Assign top periods to variables
```{r}
NO.p1 <- sorted.Ts.NO[1]
NO.p2 <- sorted.Ts.NO[2]
NO.p3 <- sorted.Ts.NO[3]
NO.p4 <- sorted.Ts.NO[4]
NO.p5 <- sorted.Ts.NO[5]
NO.p6 <- sorted.Ts.NO[6]
NO.p7 <- sorted.Ts.NO[7]
NO.p8 <- sorted.Ts.NO[8]
NO.p9 <- sorted.Ts.NO[9]
NO.p10 <- sorted.Ts.NO[10]
NO.p11 <- sorted.Ts.NO[11]
NO.p12 <- sorted.Ts.NO[12]
NO.p13 <- sorted.Ts.NO[13]
NO.p14 <- sorted.Ts.NO[14]
NO.p15 <- sorted.Ts.NO[15]

NO.pavg1 <- mean(c(sorted.Ts.NO[8],sorted.Ts.NO[9], sorted.Ts.NO[10], sorted.Ts.NO[11]))
NO.pavg2 <- mean(c(sorted.Ts.NO[12],sorted.Ts.NO[13], sorted.Ts.NO[14], sorted.Ts.NO[15]))
```

NO Model for top 3 Periods
```{r}
# create time variable
time.NO<-c(1:length(NO.ts))

# actual model
NO.lm.top3 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3)) 

# model summary
summary(NO.lm.top3)
```
NO Model for top 5 Periods
```{r}
# actual model
NO.lm.top5 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5)) 

# model summary
summary(NO.lm.top5)
```
NO Model for top 10 Periods
```{r}
# actual model
NO.lm.top10 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10)) 

# model summary
summary(NO.lm.top10)
```
NO Model for top 15 Periods
```{r}
# actual model
NO.lm.top15 <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) + 
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.p8) + 
                         cos(2*pi*time.NO/NO.p8) +
                         sin(2*pi*time.NO/NO.p9) + 
                         cos(2*pi*time.NO/NO.p9) +
                         sin(2*pi*time.NO/NO.p10) + 
                         cos(2*pi*time.NO/NO.p10) +
                         sin(2*pi*time.NO/NO.p11) + 
                         cos(2*pi*time.NO/NO.p11) + 
                         sin(2*pi*time.NO/NO.p12) + 
                         cos(2*pi*time.NO/NO.p12) +
                         sin(2*pi*time.NO/NO.p13) + 
                         cos(2*pi*time.NO/NO.p13) +
                         sin(2*pi*time.NO/NO.p14) + 
                         cos(2*pi*time.NO/NO.p14) +
                         sin(2*pi*time.NO/NO.p15) + 
                         cos(2*pi*time.NO/NO.p15)) 

# model summary
summary(NO.lm.top15)
```
NO Model with Averaged Periods 
```{r}
NO.lm.combined <- lm(NO.ts ~ sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2)) 

# model summary
summary(NO.lm.combined)
```

Model Comparison
```{r}
anova(NO.lm.top3, NO.lm.top5)
#small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top5, NO.lm.top10)
#small p-value suggests that the larger model performs better than the smaller model 

anova(NO.lm.top10, NO.lm.top15)
#large p-value suggests that the smaller model performs better 

anova(NO.lm.top10, NO.lm.combined)
#large p-value suggests that the smaller model performs better 

anova(NO.lm.combined, NO.lm.top5)
#small p-value suggests that the larger model performs better
```

<<<<<<< HEAD
The partial-F tests suggest that the largest model, the one with 10 periods included, is the best predictor of the time series 

Visually inspect step model 
```{r}
plot(NO.ts)
lines(NO.lm.top3$fitted.values, col = "red")
lines(NO.lm.top5$fitted.values, col = "blue")
lines(NO.lm.top10$fitted.values, col = "green")
lines(NO.lm.combined$fitted.values, col = "orange")

legend(0, 350, legend = c("Top 3 Periods", "Top 5 Periods", "Top 10 Periods", "Combined Periods"), col = c("red", "blue", "green", "orange"), lwd = 1)
```
The graph suggests that the model that contains the combined periods is the best predictor

Visual Inspection of the Combined Periods 
```{r}
plot(NO.ts)
lines(NO.lm.combined$fitted.values, col = "blue")
```
<!-- ======= -->
<!-- # Multivariate Time Series -->
<!-- ## Seasonality -->
<!-- ## Trend -->
<!-- ## Autoregressive and Moving Average Components -->
<!-- ### Metrics -->
<!-- compare models based on adjusted R2 and/or AIC -->
<!-- ### Diagnostics -->
<!-- diagnostics of linear models of trends + seasonality and ARIMA models of residuals -->
<!-- ### Forecasting -->
<!-- compare models based on MSE -->

<!-- ## Final Model -->

<!-- ## Diagnostics -->
<!-- what problems remain in the diagnostics of the selected model? -->
<!-- >>>>>>> 612d638bd48f774931f36b03e39d80ee4e4cc0a5 -->

Determine if there is a trend in the data 
```{r}
# the actual model
NO.lm.trend <- lm(NO.ts ~ time.NO)

# summary analysis
summary(NO.lm.trend)

plot(time.NO, NO.ts, type = "l")
abline(NO.lm.trend, col = "red")
```
This shows that there is a trend in the data 

Make a combined model of seasonality and trend 
```{r}
NO.trendseason <- lm(NO.ts ~ time.NO + sin(2*pi*time.NO/NO.p1) + 
                         cos(2*pi*time.NO/NO.p1) +
                         sin(2*pi*time.NO/NO.p2) + 
                         cos(2*pi*time.NO/NO.p2) +
                         sin(2*pi*time.NO/NO.p3) + 
                         cos(2*pi*time.NO/NO.p3) +
                         sin(2*pi*time.NO/NO.p4) + 
                         cos(2*pi*time.NO/NO.p4) +
                         sin(2*pi*time.NO/NO.p5) + 
                         cos(2*pi*time.NO/NO.p5) +
                         sin(2*pi*time.NO/NO.p6) + 
                         cos(2*pi*time.NO/NO.p6) +
                         sin(2*pi*time.NO/NO.p7) + 
                         cos(2*pi*time.NO/NO.p7) +
                         sin(2*pi*time.NO/NO.pavg1) + 
                         cos(2*pi*time.NO/NO.pavg1) +
                         sin(2*pi*time.NO/NO.pavg2) + 
                         cos(2*pi*time.NO/NO.pavg2))

summary(NO.trendseason)

plot(NO.ts)
lines(NO.trendseason$fitted.values, col = "blue")
lines(NO.lm.combined$fitted.values, col = "red")

anova(NO.trendseason, NO.lm.combined)

```
Decided to proceed using the model that incorporates trend and seasonality 

ARIMA Model 
```{r}
e.ts.NO <- NO.trendseason$residuals
acf(e.ts.NO)
#Because there is no linear decay in the ACF then the residuals are stationary
#cuts off after 2 lags
pacf(e.ts.NO)
#cuts off after 1 or 5 lags 
```
Make ARIMA models 
```{r}
NO.arima201 <- arima(e.ts.NO, order = c(2,0,1), include.mean = FALSE)
NO.arima205 <- arima(e.ts.NO, order = c(2,0,5), include.mean = FALSE)
NO.arima.auto <- auto.arima(e.ts.NO, approximation = FALSE)
```

Compare ARIMA Mdoels 
```{r}
#Compare Visually - Not sure if this is a legit way of doing this
plot(e.ts.NO, type = "line")
lines(NO.arima201$residuals,col = "red")
plot(e.ts.NO, type = "line")
lines(NO.arima205$residuals,col = "blue")
plot(e.ts.NO, type = "line")
lines(NO.arima.auto$residuals,col = "green")

#AIC
AIC(NO.arima201)
AIC(NO.arima205)
AIC(NO.arima.auto)

#BIC
BIC(NO.arima201)
BIC(NO.arima205)
BIC(NO.arima.auto)

#Diagnostics
tsdiag(NO.arima201, gof.lag = 20)
tsdiag(NO.arima205, gof.lag = 20)
tsdiag(NO.arima.auto, gof.lag = 20)

```














=======
# Simulation from Univariate CO Model
```{r}
# CO univariate model = model of data + model of residuals
CO.uni <- CO.final + CO.resi.final # idk that this is the way to do this

# simulate 1 year of daily maximum CO concentrations
### fix this based on actual ar and ma terms
CO.uni.sim <- arima.sim(n = 365*1, list(ar = c(CO.uni$coef[1], CO.uni$coef[2]), ma = c(CO.uni$coef[3])), sd = sqrt(CO.uni$sigma2))

# make time series
CO.uni.sim.ts <- ts(CO.uni.sim)
```

## Visualization
```{r}
# plot simulated values with observations
plot(CO.ts, main = "Simulation from Univariate CO Model", col = "black")
lines(CO.uni.sim.ts, col = "red")
legend(0.6, 0.57, legend = c("Time Series Data", "Simulation"), col = c("black", "red"))
```
how does simulation compare visually with time series data?

## Trend
```{r}
# linear model for simulation
CO.sim.lm <- lm()
```
compare coefficient estimates

## Seasonality
```{r}
# compare periodogram of observations and periodogram of simulation
par(mfrow = c(1,2))
pg.CO
pg.CO.uni.sim <- spec.pgram(CO.uni.sim.ts, spans = 9, demean = T, log = 'no')
par(mfrow = c(1,1))
```
compare periodograms (get periods?)

## Mean and Variance
```{r}
# mean of observations
mean(CO.ts)

# mean of simulation
mean(CO.uni.sim.ts)

# variance of observations
var(CO.ts)

# variance of simulation
var(CO.uni.sim.ts)
```
compare mean and variance

## Auto-Correlation
```{r}
# ACF of observations
acf(CO.ts)

# ACF of simulation
acf(CO.uni.sim.ts)
```
compare ACF

```{r}
# PACF of observations
pacf(CO.ts)

# PACF of simulation
pacf(CO.uni.sim.ts)
```
compare PACF

## Cross-Correlation
```{r}
# cross-correlation of observations
cor(air.train$CO.GT.)

# cross-correlation of simulation
cor(CO.uni.sim)
```
compare cross-correlation

# Simulation from Univariate NO2 Model
## Visualization
## Trend
## Seasonality
## Mean and Variance
## Auto-Correlation
## Cross-Correlation


# Simulation from Multivariate Model
## Visualization
## Trend
## Seasonality
## Mean and Variance
## Auto-Correlation
## Cross-Correlation

